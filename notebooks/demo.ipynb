{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73541e6c-f4d8-4ed5-bfee-bbf10d1072e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4032d086-3eaf-48d3-8adf-5c350afc06d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "parent_directory = os.path.abspath('..')\n",
    "sys.path.append(parent_directory)\n",
    "\n",
    "from actionweaver.llms import patch\n",
    "from langchain_community.utilities.github import GitHubAPIWrapper\n",
    "from langsmith.run_helpers import traceable\n",
    "\n",
    "from autocoder.bot import AutoCoder\n",
    "from autocoder.index import RepositoryIndex\n",
    "\n",
    "from autocoder.codebase import Codebase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8cd3dc08-68d8-49a9-95c4-f1d5a1c178d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing codebase TengHu/AutoCoder\n",
      "Indexing autocoder/__init__.py\n",
      "Indexing autocoder/bot.py\n",
      "Indexing autocoder/codebase.py\n",
      "Indexing autocoder/pydantic_models.py\n",
      "Indexing autocoder/pydantic_models_v2.py\n",
      "Indexing autocoder/rag.py\n",
      "Indexing autocoder/telemetry.py\n",
      "Indexing main.py\n"
     ]
    }
   ],
   "source": [
    "github_repository = \"TengHu/AutoCoder\"\n",
    "github_api = GitHubAPIWrapper(\n",
    "    github_repository=github_repository,\n",
    "    github_app_id=os.environ[\"GITHUB_APP_ID\"],\n",
    "    github_app_private_key=os.environ[\"GITHUB_APP_PRIVATE_KEY\"],\n",
    ")\n",
    "codebase = Codebase(github_api)\n",
    "index = RepositoryIndex(github_api, github_repository, codebase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5137b4db-2208-4faf-a479-17076da18e9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[System] Branch 'aw_demo_bot_v4' created successfully, and set as current active branch.\n"
     ]
    }
   ],
   "source": [
    "auto_coder = AutoCoder(github_api, index, codebase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb2f3d9-c7ee-486b-a889-a645969bb45b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bad6fbc4-e66a-408e-867d-b617b6703275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The `two_sum.py` file has been created with three different solutions for the two-sum problem. Below is the content of the file:\n",
      "\n",
      "```python\n",
      "# Solution 1: Brute Force Approach\n",
      "# Time Complexity: O(n^2)\n",
      "def two_sum_brute_force(nums, target):\n",
      "    for i in range(len(nums)):\n",
      "        for j in range(i + 1, len(nums)):\n",
      "            if nums[i] + nums[j] == target:\n",
      "                return [i, j]\n",
      "    return []\n",
      "\n",
      "# Solution 2: Hash Table Approach\n",
      "# Time Complexity: O(n)\n",
      "def two_sum_hash_table(nums, target):\n",
      "    hash_table = {}\n",
      "    for i, num in enumerate(nums):\n",
      "        complement = target - num\n",
      "        if complement in hash_table:\n",
      "            return [hash_table[complement], i]\n",
      "        hash_table[num] = i\n",
      "    return []\n",
      "\n",
      "# Solution 3: Two-Pointer Technique for Sorted Array\n",
      "# Time Complexity: O(n)\n",
      "# Note: This solution assumes the input array is already sorted.\n",
      "def two_sum_two_pointer(nums, target):\n",
      "    left, right = 0, len(nums) - 1\n",
      "    while left < right:\n",
      "        current_sum = nums[left] + nums[right]\n",
      "        if current_sum == target:\n",
      "            return [left, right]\n",
      "        elif current_sum < target:\n",
      "            left += 1\n",
      "        else:\n",
      "            right -= 1\n",
      "    return []\n",
      "\n",
      "# Example usage:\n",
      "if __name__ == \"__main__\":\n",
      "    nums = [2, 7, 11, 15]\n",
      "    target = 9\n",
      "    print(two_sum_brute_force(nums, target))  # Output: [0, 1]\n",
      "    print(two_sum_hash_table(nums, target))   # Output: [0, 1]\n",
      "    # For two_sum_two_pointer, the array must be sorted\n",
      "    print(two_sum_two_pointer(sorted(nums), target))  # Output: [0, 1]\n",
      "```\n",
      "\n",
      "You can run this file in your Python environment to test the different solutions to the two-sum problem. If you need further assistance or modifications, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "res = auto_coder(\"Create two_sum.py with 3 solutions for two sum problem\")\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73751d5b-cfaa-4885-8445-746a551da29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_coder(\"create a pr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d16a64d-de27-430f-b742-7c045af08813",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = index.query(\"AutoCoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9d3d0e-232b-4f61-98a1-7eab421d7e37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "26a71e4f-054c-46d7-8a43-66b07fed9971",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai.types.chat.chat_completion_message import ChatCompletionMessage\n",
    "from openai.types.chat.chat_completion_message_tool_call import (\n",
    "    ChatCompletionMessageToolCall,\n",
    "Function\n",
    ")\n",
    "messages = [{'role': 'system',\n",
    "  'content': 'You are a coding assistant, you have the capability to assist with code-related tasks and modify files.'},\n",
    " {'role': 'user', 'content': 'Move trace_client function to bot.py.'},\n",
    " ChatCompletionMessage(content=None, role='assistant', tool_calls=[ChatCompletionMessageToolCall(id='call_9f2agXdE5nnUl1X04XkYHjeQ', function=Function(arguments='{\"description\":\"Move the \\'trace_client\\' function from its current location to the \\'bot.py\\' file.\"}', name='PlanCodeChange'), type='function')]),\n",
    " {'tool_call_id': 'call_9f2agXdE5nnUl1X04XkYHjeQ',\n",
    "  'role': 'tool',\n",
    "  'name': 'PlanCodeChange',\n",
    "  'content': \"- New files created: []\\n        - Existing files updated: [['Updated file autocoder/bot.py', 'Updated file autocoder/telemetry.py']]\\n        - Problems encountered: []\\n        ###\\n    Ignore others,    Make the previous message more user-friendly\\n        \"}\n",
    "           ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a1db6eea-8727-4b79-b971-217875e64fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "\n",
    "client = OpenAI()\n",
    "response = client.chat.completions.create(\n",
    "            model=\"gpt-4-1106-preview\",\n",
    "            messages=messages,\n",
    "            stream=False,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6933b5be-f2cb-42c8-8f10-e1ce1f89761e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-8h2sHwJwIR8SOkWxw2ypBGd80Uyom', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='I can assist you with moving the `trace_client` function to `bot.py`, but I need access to the source code or need to know where the current `trace_client` function is located. Can you provide the current code file that contains the `trace_client` function or tell me where to find it?', role='assistant', function_call=None, tool_calls=None))], created=1705269845, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_168383a679', usage=CompletionUsage(completion_tokens=63, prompt_tokens=135, total_tokens=198))\n"
     ]
    }
   ],
   "source": [
    "print (response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "09cb5b10-eda9-46e0-994d-60b2c5f86fb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I can assist you with moving the `trace_client` function to `bot.py`, but I need access to the source code or need to know where the current `trace_client` function is located. Can you provide the current code file that contains the `trace_client` function or tell me where to find it?\n"
     ]
    }
   ],
   "source": [
    "print (response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "50c37b99-db67-4367-8771-a284e4dfab57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a coding assistant, you have the capability to assist with code-related tasks and modify files.\n"
     ]
    }
   ],
   "source": [
    "print (messages[0]['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "df5b7a06-951b-4cc2-b7d2-cbbc864410b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': 'You are a coding assistant, you have the capability to assist with code-related tasks and modify files.'},\n",
       " {'role': 'user', 'content': 'Move trace_client function to bot.py.'},\n",
       " ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_9f2agXdE5nnUl1X04XkYHjeQ', function=Function(arguments='{\"description\":\"Move the \\'trace_client\\' function from its current location to the \\'bot.py\\' file.\"}', name='PlanCodeChange'), type='function')]),\n",
       " {'tool_call_id': 'call_9f2agXdE5nnUl1X04XkYHjeQ',\n",
       "  'role': 'tool',\n",
       "  'name': 'PlanCodeChange',\n",
       "  'content': \"I've read code and attempted to create code changes. The outcome of these code changes is as follows:\\n        - New files created: []\\n        - Existing files updated: [['Updated file autocoder/bot.py', 'Updated file autocoder/telemetry.py']]\\n        - Problems encountered: []\\n        ###\\n        Make the previous message more user-friendly\\n        \"}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ad5c605-9071-40a9-bd36-d8a6735cd25a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "user_prompt = '''\n",
    "CONTEXT FOR MAKING CODE MODIFICATIONS:\n",
    "\n",
    "###############\n",
    "This section is divider and not a part of the code.\n",
    "Code Snippet From Filepath: autocoder/bot.py\n",
    "#############\n",
    "\n",
    "class AutoCoder:\n",
    "<END OF SNIPPET>\n",
    "###############\n",
    "This section is divider and not a part of the code.\n",
    "Code Snippet From Filepath: autocoder/bot.py\n",
    "#############\n",
    "\n",
    "import datetime\n",
    "import os\n",
    "import uuid\n",
    "from typing import List, Union\n",
    "\n",
    "from actionweaver import action\n",
    "from actionweaver.utils.tokens import TokenUsageTracker\n",
    "from langchain_community.utilities.github import GitHubAPIWrapper\n",
    "from langsmith.run_helpers import traceable\n",
    "from llama_index import Document, ServiceContext, VectorStoreIndex\n",
    "from llama_index.node_parser import CodeSplitter\n",
    "from openai import AzureOpenAI, OpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from autocoder.pydantic_models import create_context, create_tasks\n",
    "from autocoder.telemetry import trace_client\n",
    "\n",
    "assert os.environ[\"MODEL\"]\n",
    "MODEL = os.environ[\"MODEL\"]\n",
    "\n",
    "\n",
    "DIVIDING_LINE = \"\"\"\n",
    "###############\n",
    "This section is divider and not a part of the code.\n",
    "{input}\n",
    "#############\n",
    "\n",
    "\"\"\"\n",
    "<END OF SNIPPET>\n",
    "###############\n",
    "This section is divider and not a part of the code.\n",
    "Code Snippet From Filepath: autocoder/bot.py\n",
    "#############\n",
    "\n",
    "@traceable(run_type=\"tool\")\n",
    "    def gather_context(self, input):\n",
    "        user_prompt = input\n",
    "\n",
    "        messages = [\n",
    "            # {\n",
    "            #     \"role\": \"system\",\n",
    "            #     \"content\": \"You are good at extract information from description\",\n",
    "            # },\n",
    "            {\"role\": \"user\", \"content\": f\"Description: {user_prompt}\"},\n",
    "        ]\n",
    "        context = create_context.invoke(\n",
    "            self.client,\n",
    "            messages=messages,\n",
    "            model=MODEL,\n",
    "            stream=False,\n",
    "            force=True,\n",
    "        )\n",
    "\n",
    "        if isinstance(context, list):\n",
    "            context = context[0]\n",
    "\n",
    "        index_response = \"\"\n",
    "        for query in context.queries + context.instructions:\n",
    "            nodes = self.index.query(query)\n",
    "            for node in nodes:\n",
    "                index_response = (\n",
    "                    index_response\n",
    "                    + DIVIDING_LINE.format(\n",
    "                        input=f\"Code Snippet From Filepath: {node.metadata['file']}\"\n",
    "                    )\n",
    "                    + f\"{node.text}\\n\"\n",
    "                    + \"<END OF SNIPPET>\"\n",
    "                )\n",
    "\n",
    "        file_response = self.read_files(context.files)\n",
    "        code_search_response = self.search_code(\" \".join(context.code_snippets))\n",
    "\n",
    "        return (\n",
    "            \"CONTEXT FOR MAKING CODE MODIFICATIONS:\\n\"\n",
    "            + index_response\n",
    "            + \"\\n\"\n",
    "            + file_response\n",
    "            + \"\\n\"\n",
    "            + code_search_response\n",
    "        )\n",
    "<END OF SNIPPET>\n",
    "###############\n",
    "This section is divider and not a part of the code.\n",
    "Code Snippet From Filepath: autocoder/bot.py\n",
    "#############\n",
    "\n",
    "@action(name=\"QuestionAnswer\", decorators=[traceable(run_type=\"tool\")])\n",
    "    def question_answer(self, rewritten_query: str, keywords: List[str]):\n",
    "        \"\"\"Answer questions about the codebase\"\"\"\n",
    "\n",
    "        context = self.gather_context(\" \".join(keywords))\n",
    "\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"{context} \\n###########\\n Question: {rewritten_query}\",\n",
    "            }\n",
    "        ]\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=MODEL,\n",
    "            messages=messages,\n",
    "            stream=False,\n",
    "            token_usage_tracker=TokenUsageTracker(500),\n",
    "        )\n",
    "        return response\n",
    "\n",
    "    @action(name=\"GetIssues\", decorators=[traceable(run_type=\"tool\")])\n",
    "    def get_issues(self):\n",
    "        \"\"\"\n",
    "        Get a list of issues from the GitHub repo.\n",
    "        \"\"\"\n",
    "        response = self.github_api.get_issues()\n",
    "        response = response.split(\"\\n\")\n",
    "        return eval(response[1]) if len(response) > 1 else []\n",
    "\n",
    "    @action(name=\"CreateGitBranch\", decorators=[traceable(run_type=\"tool\")])\n",
    "    def create_branch(self, branch: str):\n",
    "        \"\"\"\n",
    "        Create a new Git branch.\n",
    "        \"\"\"\n",
    "        return self.github_api.create_branch(branch)\n",
    "<END OF SNIPPET>\n",
    "###############\n",
    "This section is divider and not a part of the code.\n",
    "Code Snippet From Filepath: autocoder/bot.py\n",
    "#############\n",
    "\n",
    "@action(\"PlanCodeChange\", stop=True, decorators=[traceable(run_type=\"tool\")])\n",
    "    def plan_code_change(self, description: str):\n",
    "        \"\"\"\n",
    "        Plan code changes based on a given description.\n",
    "\n",
    "        This method is designed to handle various types of code alterations such as\n",
    "        inserting new code, refactoring existing code, replacing segments, or making\n",
    "        general modifications.\n",
    "        \"\"\"\n",
    "        context = self.gather_context(description)\n",
    "\n",
    "        user_prompt = f\"\"\"\n",
    "        {context}\n",
    "        {'#' * 20}\n",
    "        Description:\n",
    "        {description}\"\"\"\n",
    "\n",
    "        messages = [{\"role\": \"user\", \"content\": user_prompt}]\n",
    "        tasks = create_tasks.invoke(\n",
    "            self.client,\n",
    "            messages=messages,\n",
    "            temperature=0.1,\n",
    "            model=MODEL,\n",
    "            stream=False,\n",
    "            force=True,\n",
    "        )\n",
    "\n",
    "        if isinstance(tasks, list):\n",
    "            tasks = tasks[0]\n",
    "        messages = tasks.execute(self.client, self.github_api, context)\n",
    "\n",
    "        files_updated = []\n",
    "        files_created = []\n",
    "        problems = []\n",
    "        for msg in messages:\n",
    "            if \"Updated file\" in str(msg):\n",
    "                files_updated.append(msg)\n",
    "            elif \"Created file\" in str(msg):\n",
    "                files_created.append(msg)\n",
    "            else:\n",
    "                problems.append(msg)\n",
    "\n",
    "        return self.rephrase(\n",
    "            f\"\"\"\n",
    "- New files created: {files_created}\n",
    "- Existing files updated: {files_updated}\n",
    "- Problems encountered: {problems}\n",
    "\"\"\"\n",
    "        )\n",
    "<END OF SNIPPET>\n",
    "###############\n",
    "This section is divider and not a part of the code.\n",
    "Code Snippet From Filepath: autocoder/bot.py\n",
    "#############\n",
    "\n",
    "def search_code(self, query: str):\n",
    "        return self.github_api.search_code(query)\n",
    "<END OF SNIPPET>\n",
    "###############\n",
    "This section is divider and not a part of the code.\n",
    "Code Snippet From Filepath: autocoder/pydantic_models.py\n",
    "#############\n",
    "\n",
    "CREATE_TASKS_PROMPT = \"Create a list of coding tasks, each task can be accomplished by modifying existing files or creating new ones\"\n",
    "create_tasks = action_from_model(\n",
    "    TaskPlan,\n",
    "    name=\"TaskPlan\",\n",
    "    description=CREATE_TASKS_PROMPT,\n",
    "    stop=True,\n",
    "    decorators=[traceable(run_type=\"tool\")],\n",
    ")\n",
    "\n",
    "\n",
    "class Context(BaseModel):\n",
    "    instructions: List[str] = Field(\n",
    "        default=[], description=\"Instructions relevant to the task.\"\n",
    "    )\n",
    "    queries: List[str] = Field(\n",
    "        default=[],\n",
    "        description=\"List of queries used to extract information from the codebase, encompassing elements such as function names, class names, import statements, variable names, and error messages, all relevant to the task.\",\n",
    "    )\n",
    "    code_snippets: List[str] = Field(\n",
    "        default=[],\n",
    "        description=\"Search for the code within the codebase.\",\n",
    "    )\n",
    "    files: List[str] = Field(default=[], description=\"List of files, e.g. *.py\")\n",
    "\n",
    "\n",
    "CREATE_CONTEXT_PROMPT = \"Extract essential details to request more context\"\n",
    "create_context = action_from_model(\n",
    "    Context,\n",
    "    name=\"Context\",\n",
    "    description=CREATE_CONTEXT_PROMPT,\n",
    "    stop=True,\n",
    "    decorators=[traceable(run_type=\"tool\")],\n",
    ")\n",
    "\n",
    "DIVIDING_LINE = \"\"\"\n",
    "###############\n",
    "This section is divider and not a part of the code.\n",
    "# {input}\n",
    "#############\n",
    "\"\"\"\n",
    "<END OF SNIPPET>\n",
    "###############\n",
    "This section is divider and not a part of the code.\n",
    "Code Snippet From Filepath: autocoder/rag.py\n",
    "#############\n",
    "\n",
    "class RepositoryIndex:\n",
    "    def __init__(self, github_api, github_repository):\n",
    "        self.github_api = github_api\n",
    "\n",
    "        content = self.github_api.list_files_in_main_branch()\n",
    "        files = content.split(\"\\n\")[1:]\n",
    "        self.files = [file for file in files if \".py\" in file]\n",
    "\n",
    "        print(f\"Indexing codebase {github_repository}\")\n",
    "        self.documents = []\n",
    "        for i, file in enumerate(self.files):\n",
    "            print(f\"Indexing {file}\")\n",
    "            text = self.github_api.read_file(file)\n",
    "            loc = len([line for line in text.split(\"\\n\") if bool(line)])\n",
    "            # TODO: incorporate last_update_time and number_of_commits in metadata\n",
    "            self.documents.append(\n",
    "                Document(text=text, metadata={\"file\": file, \"loc\": loc})\n",
    "            )\n",
    "\n",
    "        code_splitter = CodeSplitter(language=\"python\", chunk_lines_overlap=25)\n",
    "        service_context = ServiceContext.from_defaults(text_splitter=code_splitter)\n",
    "        self.index = VectorStoreIndex.from_documents(\n",
    "            self.documents, service_context=service_context\n",
    "        )\n",
    "\n",
    "    def query(self, text: str):\n",
    "        query_engine = self.index.as_query_engine(\n",
    "            similarity_top_k=10, response_mode=\"no_text\"\n",
    "        )\n",
    "        response = query_engine.query(text)\n",
    "\n",
    "        nodes = response.source_nodes\n",
    "\n",
    "        # ranking by score and line of codes\n",
    "        nodes.sort(key=lambda n: n.score + n.metadata[\"loc\"], reverse=True)\n",
    "        return nodes\n",
    "<END OF SNIPPET>\n",
    "###############\n",
    "This section is divider and not a part of the code.\n",
    "Code Snippet From Filepath: autocoder/rag.py\n",
    "#############\n",
    "\n",
    "from llama_index import Document, ServiceContext, VectorStoreIndex\n",
    "from llama_index.node_parser import CodeSplitter\n",
    "<END OF SNIPPET>\n",
    "###############\n",
    "This section is divider and not a part of the code.\n",
    "Code Snippet From Filepath: main.py\n",
    "#############\n",
    "\n",
    "import os\n",
    "\n",
    "from actionweaver.llms import patch\n",
    "from bot import AutoCoder\n",
    "from langchain_community.utilities.github import GitHubAPIWrapper\n",
    "from langsmith.run_helpers import traceable\n",
    "\n",
    "from autocoder.rag import RepositoryIndex\n",
    "\n",
    "assert os.environ[\"LANGCHAIN_API_KEY\"]\n",
    "assert os.environ[\"GITHUB_APP_ID\"]\n",
    "assert os.environ[\"GITHUB_APP_PRIVATE_KEY\"]\n",
    "\n",
    "# If use OpenAI API\n",
    "assert os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "\n",
    "project_name = \"autocoder\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = project_name  # Optional: \"default\" is used if not set\n",
    "\n",
    "\n",
    "github_repository = \"TengHu/auto_coder\"\n",
    "github_api = GitHubAPIWrapper(\n",
    "    github_repository=github_repository,\n",
    "    github_app_id=os.environ[\"GITHUB_APP_ID\"],\n",
    "    github_app_private_key=os.environ[\"GITHUB_APP_PRIVATE_KEY\"],\n",
    ")\n",
    "\n",
    "index = RepositoryIndex(github_api, github_repository)\n",
    "\n",
    "auto_coder = AutoCoder(github_api, None)\n",
    "res = auto_coder(\"What are the open issues?\")\n",
    "print(res)\n",
    "<END OF SNIPPET>\n",
    "\n",
    "###############\n",
    "This section is divider and not a part of the code.\n",
    "Content From Filepath: autocoder/bot.py\n",
    "#############\n",
    "\n",
    "import datetime\n",
    "import os\n",
    "import uuid\n",
    "from typing import List, Union\n",
    "\n",
    "from actionweaver import action\n",
    "from actionweaver.utils.tokens import TokenUsageTracker\n",
    "from langchain_community.utilities.github import GitHubAPIWrapper\n",
    "from langsmith.run_helpers import traceable\n",
    "from llama_index import Document, ServiceContext, VectorStoreIndex\n",
    "from llama_index.node_parser import CodeSplitter\n",
    "from openai import AzureOpenAI, OpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from autocoder.pydantic_models import create_context, create_tasks\n",
    "from autocoder.telemetry import trace_client\n",
    "\n",
    "assert os.environ[\"MODEL\"]\n",
    "MODEL = os.environ[\"MODEL\"]\n",
    "\n",
    "\n",
    "DIVIDING_LINE = \"\"\"\n",
    "###############\n",
    "This section is divider and not a part of the code.\n",
    "{input}\n",
    "#############\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class AutoCoder:\n",
    "    def __init__(self, github_api, index):\n",
    "        self.github_api = github_api\n",
    "\n",
    "        # self.client = trace_client(AzureOpenAI(\n",
    "        #     azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "        #     api_key=os.getenv(\"AZURE_OPENAI_KEY\"),\n",
    "        #     api_version=\"2023-10-01-preview\"\n",
    "        # ))\n",
    "        self.client = trace_client(OpenAI())\n",
    "        self.messages = [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a coding assistant, you have the capability to assist with code-related tasks and modify files.\",\n",
    "            },\n",
    "        ]\n",
    "        self.index = index\n",
    "\n",
    "        msg = self.create_branch(f\"aw_demo_bot\")\n",
    "        print(f\"[System] {msg}\")\n",
    "\n",
    "    def __call__(self, input: str):\n",
    "        self.messages.append({\"role\": \"user\", \"content\": input})\n",
    "\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=MODEL,\n",
    "            messages=self.messages,\n",
    "            stream=False,\n",
    "            temperature=0.1,\n",
    "            actions=[\n",
    "                self.get_issues,\n",
    "                self.question_answer,\n",
    "                self.create_pull_request,\n",
    "                self.plan_code_change,\n",
    "            ],\n",
    "            orch={\n",
    "                self.plan_code_change.name: None,\n",
    "                self.create_pull_request.name: None,\n",
    "            },\n",
    "            token_usage_tracker=TokenUsageTracker(500),\n",
    "        )\n",
    "\n",
    "        content = \"\"\n",
    "        try:\n",
    "            content = response.choices[0].message.content\n",
    "        except:\n",
    "            content = str(response)\n",
    "        self.messages.append({\"role\": \"assistant\", \"content\": content})\n",
    "        return content\n",
    "\n",
    "    @traceable(run_type=\"tool\")\n",
    "    def gather_context(self, input):\n",
    "        user_prompt = input\n",
    "\n",
    "        messages = [\n",
    "            # {\n",
    "            #     \"role\": \"system\",\n",
    "            #     \"content\": \"You are good at extract information from description\",\n",
    "            # },\n",
    "            {\"role\": \"user\", \"content\": f\"Description: {user_prompt}\"},\n",
    "        ]\n",
    "        context = create_context.invoke(\n",
    "            self.client,\n",
    "            messages=messages,\n",
    "            model=MODEL,\n",
    "            stream=False,\n",
    "            force=True,\n",
    "        )\n",
    "\n",
    "        if isinstance(context, list):\n",
    "            context = context[0]\n",
    "\n",
    "        index_response = \"\"\n",
    "        for query in context.queries + context.instructions:\n",
    "            nodes = self.index.query(query)\n",
    "            for node in nodes:\n",
    "                index_response = (\n",
    "                    index_response\n",
    "                    + DIVIDING_LINE.format(\n",
    "                        input=f\"Code Snippet From Filepath: {node.metadata['file']}\"\n",
    "                    )\n",
    "                    + f\"{node.text}\\n\"\n",
    "                    + \"<END OF SNIPPET>\"\n",
    "                )\n",
    "\n",
    "        file_response = self.read_files(context.files)\n",
    "        code_search_response = self.search_code(\" \".join(context.code_snippets))\n",
    "\n",
    "        return (\n",
    "            \"CONTEXT FOR MAKING CODE MODIFICATIONS:\\n\"\n",
    "            + index_response\n",
    "            + \"\\n\"\n",
    "            + file_response\n",
    "            + \"\\n\"\n",
    "            + code_search_response\n",
    "        )\n",
    "\n",
    "    @action(name=\"QuestionAnswer\", decorators=[traceable(run_type=\"tool\")])\n",
    "    def question_answer(self, rewritten_query: str, keywords: List[str]):\n",
    "        \"\"\"Answer questions about the codebase\"\"\"\n",
    "\n",
    "        context = self.gather_context(\" \".join(keywords))\n",
    "\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"{context} \\n###########\\n Question: {rewritten_query}\",\n",
    "            }\n",
    "        ]\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=MODEL,\n",
    "            messages=messages,\n",
    "            stream=False,\n",
    "            token_usage_tracker=TokenUsageTracker(500),\n",
    "        )\n",
    "        return response\n",
    "\n",
    "    @action(name=\"GetIssues\", decorators=[traceable(run_type=\"tool\")])\n",
    "    def get_issues(self):\n",
    "        \"\"\"\n",
    "        Get a list of issues from the GitHub repo.\n",
    "        \"\"\"\n",
    "        response = self.github_api.get_issues()\n",
    "        response = response.split(\"\\n\")\n",
    "        return eval(response[1]) if len(response) > 1 else []\n",
    "\n",
    "    @action(name=\"CreateGitBranch\", decorators=[traceable(run_type=\"tool\")])\n",
    "    def create_branch(self, branch: str):\n",
    "        \"\"\"\n",
    "        Create a new Git branch.\n",
    "        \"\"\"\n",
    "        return self.github_api.create_branch(branch)\n",
    "\n",
    "    @action(name=\"CreatePullRequest\", decorators=[traceable(run_type=\"tool\")])\n",
    "    def create_pull_request(self, title: str, description: str):\n",
    "        \"\"\"\n",
    "        Create a new Pull Request in a Git repository.\n",
    "\n",
    "        Args:\n",
    "            title (str): The title of the Pull Request.\n",
    "            description (str): The description of the Pull Request.\n",
    "        \"\"\"\n",
    "        return self.github_api.create_pull_request(pr_query=f\"{title}\\n {description}\")\n",
    "\n",
    "    @traceable(run_type=\"tool\")\n",
    "    def read_files(self, files: List[str]) -> List[str]:\n",
    "        \"\"\"\n",
    "        Read the content of multiple files in the GitHub repo\n",
    "\n",
    "        Args:\n",
    "            files (List[str]): A list of file paths to be read using the GitHub API.\n",
    "        \"\"\"\n",
    "        response = \"\"\n",
    "        for file in files:\n",
    "            api_response = self.github_api.read_file(file)\n",
    "            if f\"File not found `{file}`\" not in api_response:\n",
    "                response = (\n",
    "                    response\n",
    "                    + DIVIDING_LINE.format(input=f\"Content From Filepath: {file}\")\n",
    "                    + f\"{self.github_api.read_file(file)}\\n<END OF FILE>\"\n",
    "                )\n",
    "        return response\n",
    "\n",
    "    def rephrase(self, input: str):\n",
    "        messages = [{\"role\": \"user\", \"content\": f\"{input}\\n####\\nRephrase\"}]\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=MODEL,\n",
    "            messages=messages,\n",
    "            stream=False,\n",
    "            temperature=0.1,\n",
    "            token_usage_tracker=TokenUsageTracker(500),\n",
    "        )\n",
    "        content = \"\"\n",
    "        try:\n",
    "            content = response.choices[0].message.content\n",
    "        except:\n",
    "            content = str(response)\n",
    "        return content\n",
    "\n",
    "    @action(\"PlanCodeChange\", stop=True, decorators=[traceable(run_type=\"tool\")])\n",
    "    def plan_code_change(self, description: str):\n",
    "        \"\"\"\n",
    "        Plan code changes based on a given description.\n",
    "\n",
    "        This method is designed to handle various types of code alterations such as\n",
    "        inserting new code, refactoring existing code, replacing segments, or making\n",
    "        general modifications.\n",
    "        \"\"\"\n",
    "        context = self.gather_context(description)\n",
    "\n",
    "        user_prompt = f\"\"\"\n",
    "        {context}\n",
    "        {'#' * 20}\n",
    "        Description:\n",
    "        {description}\"\"\"\n",
    "\n",
    "        messages = [{\"role\": \"user\", \"content\": user_prompt}]\n",
    "        tasks = create_tasks.invoke(\n",
    "            self.client,\n",
    "            messages=messages,\n",
    "            temperature=0.1,\n",
    "            model=MODEL,\n",
    "            stream=False,\n",
    "            force=True,\n",
    "        )\n",
    "\n",
    "        if isinstance(tasks, list):\n",
    "            tasks = tasks[0]\n",
    "        messages = tasks.execute(self.client, self.github_api, context)\n",
    "\n",
    "        files_updated = []\n",
    "        files_created = []\n",
    "        problems = []\n",
    "        for msg in messages:\n",
    "            if \"Updated file\" in str(msg):\n",
    "                files_updated.append(msg)\n",
    "            elif \"Created file\" in str(msg):\n",
    "                files_created.append(msg)\n",
    "            else:\n",
    "                problems.append(msg)\n",
    "\n",
    "        return self.rephrase(\n",
    "            f\"\"\"\n",
    "- New files created: {files_created}\n",
    "- Existing files updated: {files_updated}\n",
    "- Problems encountered: {problems}\n",
    "\"\"\"\n",
    "        )\n",
    "\n",
    "    def search_code(self, query: str):\n",
    "        return self.github_api.search_code(query)\n",
    "\n",
    "<END OF FILE>\n",
    "Showing top 5 of 10 results:\n",
    "Filepath: `README.md`\n",
    "File contents: # auto_coder\n",
    "<END OF FILE>\n",
    "Filepath: `main.py`\n",
    "File contents: import os\n",
    "\n",
    "from actionweaver.llms import patch\n",
    "from bot import AutoCoder\n",
    "from langchain_community.utilities.github import GitHubAPIWrapper\n",
    "from langsmith.run_helpers import traceable\n",
    "\n",
    "from autocoder.rag import RepositoryIndex\n",
    "\n",
    "assert os.environ[\"LANGCHAIN_API_KEY\"]\n",
    "assert os.environ[\"GITHUB_APP_ID\"]\n",
    "assert os.environ[\"GITHUB_APP_PRIVATE_KEY\"]\n",
    "\n",
    "# If use OpenAI API\n",
    "assert os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "\n",
    "project_name = \"autocoder\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = project_name  # Optional: \"default\" is used if not set\n",
    "\n",
    "\n",
    "github_repository = \"TengHu/auto_coder\"\n",
    "github_api = GitHubAPIWrapper(\n",
    "    github_repository=github_repository,\n",
    "    github_app_id=os.environ[\"GITHUB_APP_ID\"],\n",
    "    github_app_private_key=os.environ[\"GITHUB_APP_PRIVATE_KEY\"],\n",
    ")\n",
    "\n",
    "index = RepositoryIndex(github_api, github_repository)\n",
    "\n",
    "auto_coder = AutoCoder(github_api, None)\n",
    "res = auto_coder(\"What are the open issues?\")\n",
    "print(res)\n",
    "\n",
    "<END OF FILE>\n",
    "Filepath: `autocoder/bot.py`\n",
    "File contents: import datetime\n",
    "import os\n",
    "import uuid\n",
    "from typing import List, Union\n",
    "\n",
    "from actionweaver import action\n",
    "from actionweaver.utils.tokens import TokenUsageTracker\n",
    "from langchain_community.utilities.github import GitHubAPIWrapper\n",
    "from langsmith.run_helpers import traceable\n",
    "from llama_index import Document, ServiceContext, VectorStoreIndex\n",
    "from llama_index.node_parser import CodeSplitter\n",
    "from openai import AzureOpenAI, OpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from autocoder.pydantic_models import create_context, create_tasks\n",
    "from autocoder.telemetry import trace_client\n",
    "\n",
    "assert os.environ[\"MODEL\"]\n",
    "MODEL = os.environ[\"MODEL\"]\n",
    "\n",
    "\n",
    "DIVIDING_LINE = \"\"\"\n",
    "###############\n",
    "This section is divider and not a part of the code.\n",
    "{input}\n",
    "#############\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class AutoCoder:\n",
    "    def __init__(self, github_api, index):\n",
    "        self.github_api = github_api\n",
    "\n",
    "        # self.client = trace_client(AzureOpenAI(\n",
    "        #     azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "        #     api_key=os.getenv(\"AZURE_OPENAI_KEY\"),\n",
    "        #     api_version=\"2023-10-01-preview\"\n",
    "        # ))\n",
    "        self.client = trace_client(OpenAI())\n",
    "        self.messages = [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a coding assistant, you have the capability to assist with code-related tasks and modify files.\",\n",
    "            },\n",
    "        ]\n",
    "        self.index = index\n",
    "\n",
    "        msg = self.create_branch(f\"aw_demo_bot\")\n",
    "        print(f\"[System] {msg}\")\n",
    "\n",
    "    def __call__(self, input: str):\n",
    "        self.messages.append({\"role\": \"user\", \"content\": input})\n",
    "\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=MODEL,\n",
    "            messages=self.messages,\n",
    "            stream=False,\n",
    "            temperature=0.1,\n",
    "            actions=[\n",
    "                self.get_issues,\n",
    "                self.question_answer,\n",
    "                self.create_pull_request,\n",
    "                self.plan_code_change,\n",
    "            ],\n",
    "            orch={\n",
    "                self.plan_code_change.name: None,\n",
    "                self.create_pull_request.name: None,\n",
    "            },\n",
    "            token_usage_tracker=TokenUsageTracker(500),\n",
    "        )\n",
    "\n",
    "        content = \"\"\n",
    "        try:\n",
    "            content = response.choices[0].message.content\n",
    "        except:\n",
    "            content = str(response)\n",
    "        self.messages.append({\"role\": \"assistant\", \"content\": content})\n",
    "        return content\n",
    "\n",
    "    @traceable(run_type=\"tool\")\n",
    "    def gather_context(self, input):\n",
    "        user_prompt = input\n",
    "\n",
    "        messages = [\n",
    "            # {\n",
    "            #     \"role\": \"system\",\n",
    "            #     \"content\": \"You are good at extract information from description\",\n",
    "            # },\n",
    "            {\"role\": \"user\", \"content\": f\"Description: {user_prompt}\"},\n",
    "        ]\n",
    "        context = create_context.invoke(\n",
    "            self.client,\n",
    "            messages=messages,\n",
    "            model=MODEL,\n",
    "            stream=False,\n",
    "            force=True,\n",
    "        )\n",
    "\n",
    "        if isinstance(context, list):\n",
    "            context = context[0]\n",
    "\n",
    "        index_response = \"\"\n",
    "        for query in context.queries + context.instructions:\n",
    "            nodes = self.index.query(query)\n",
    "            for node in nodes:\n",
    "                index_response = (\n",
    "                    index_response\n",
    "                    + DIVIDING_LINE.format(\n",
    "                        input=f\"Code Snippet From Filepath: {node.metadata['file']}\"\n",
    "                    )\n",
    "                    + f\"{node.text}\\n\"\n",
    "                    + \"<END OF SNIPPET>\"\n",
    "                )\n",
    "\n",
    "        file_response = self.read_files(context.files)\n",
    "        code_search_response = self.search_code(\" \".join(context.code_snippets))\n",
    "\n",
    "        return (\n",
    "            \"CONTEXT FOR MAKING CODE MODIFICATIONS:\\n\"\n",
    "            + index_response\n",
    "            + \"\\n\"\n",
    "            + file_response\n",
    "            + \"\\n\"\n",
    "            + code_search_response\n",
    "        )\n",
    "\n",
    "    @action(name=\"QuestionAnswer\", decorators=[traceable(run_type=\"tool\")])\n",
    "    def question_answer(self, rewritten_query: str, keywords: List[str]):\n",
    "        \"\"\"Answer questions about the codebase\"\"\"\n",
    "\n",
    "        context = self.gather_context(\" \".join(keywords))\n",
    "\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"{context} \\n###########\\n Question: {rewritten_query}\",\n",
    "            }\n",
    "        ]\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=MODEL,\n",
    "            messages=messages,\n",
    "            stream=False,\n",
    "            token_usage_tracker=TokenUsageTracker(500),\n",
    "        )\n",
    "        return response\n",
    "\n",
    "    @action(name=\"GetIssues\", decorators=[traceable(run_type=\"tool\")])\n",
    "    def get_issues(self):\n",
    "        \"\"\"\n",
    "        Get a list of issues from the GitHub repo.\n",
    "        \"\"\"\n",
    "        response = self.github_api.get_issues()\n",
    "        response = response.split(\"\\n\")\n",
    "        return eval(response[1]) if len(response) > 1 else []\n",
    "\n",
    "    @action(name=\"CreateGitBranch\", decorators=[traceable(run_type=\"tool\")])\n",
    "    def create_branch(self, branch: str):\n",
    "        \"\"\"\n",
    "        Create a new Git branch.\n",
    "        \"\"\"\n",
    "        return self.github_api.create_branch(branch)\n",
    "\n",
    "    @action(name=\"CreatePullRequest\", decorators=[traceable(run_type=\"tool\")])\n",
    "    def create_pull_request(self, title: str, description: str):\n",
    "        \"\"\"\n",
    "        Create a new Pull Request in a Git repository.\n",
    "\n",
    "        Args:\n",
    "            title (str): The title of the Pull Request.\n",
    "            description (str): The description of the Pull Request.\n",
    "        \"\"\"\n",
    "        return self.github_api.create_pull_request(pr_query=f\"{title}\\n {description}\")\n",
    "\n",
    "    @traceable(run_type=\"tool\")\n",
    "    def read_files(self, files: List[str]) -> List[str]:\n",
    "        \"\"\"\n",
    "        Read the content of multiple files in the GitHub repo\n",
    "\n",
    "        Args:\n",
    "            files (List[str]): A list of file paths to be read using the GitHub API.\n",
    "        \"\"\"\n",
    "        response = \"\"\n",
    "        for file in files:\n",
    "            api_response = self.github_api.read_file(file)\n",
    "            if f\"File not found `{file}`\" not in api_response:\n",
    "                response = (\n",
    "                    response\n",
    "                    + DIVIDING_LINE.format(input=f\"Content From Filepath: {file}\")\n",
    "                    + f\"{self.github_api.read_file(file)}\\n<END OF FILE>\"\n",
    "                )\n",
    "        return response\n",
    "\n",
    "    def rephrase(self, input: str):\n",
    "        messages = [{\"role\": \"user\", \"content\": f\"{input}\\n####\\nRephrase\"}]\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=MODEL,\n",
    "            messages=messages,\n",
    "            stream=False,\n",
    "            temperature=0.1,\n",
    "            token_usage_tracker=TokenUsageTracker(500),\n",
    "        )\n",
    "        content = \"\"\n",
    "        try:\n",
    "            content = response.choices[0].message.content\n",
    "        except:\n",
    "            content = str(response)\n",
    "        return content\n",
    "\n",
    "    @action(\"PlanCodeChange\", stop=True, decorators=[traceable(run_type=\"tool\")])\n",
    "    def plan_code_change(self, description: str):\n",
    "        \"\"\"\n",
    "        Plan code changes based on a given description.\n",
    "\n",
    "        This method is designed to handle various types of code alterations such as\n",
    "        inserting new code, refactoring existing code, replacing segments, or making\n",
    "        general modifications.\n",
    "        \"\"\"\n",
    "        context = self.gather_context(description)\n",
    "\n",
    "        user_prompt = f\"\"\"\n",
    "        {context}\n",
    "        {'#' * 20}\n",
    "        Description:\n",
    "        {description}\"\"\"\n",
    "\n",
    "        messages = [{\"role\": \"user\", \"content\": user_prompt}]\n",
    "        tasks = create_tasks.invoke(\n",
    "            self.client,\n",
    "            messages=messages,\n",
    "            temperature=0.1,\n",
    "            model=MODEL,\n",
    "            stream=False,\n",
    "            force=True,\n",
    "        )\n",
    "\n",
    "        if isinstance(tasks, list):\n",
    "            tasks = tasks[0]\n",
    "        messages = tasks.execute(self.client, self.github_api, context)\n",
    "\n",
    "        files_updated = []\n",
    "        files_created = []\n",
    "        problems = []\n",
    "        for msg in messages:\n",
    "            if \"Updated file\" in str(msg):\n",
    "                files_updated.append(msg)\n",
    "            elif \"Created file\" in str(msg):\n",
    "                files_created.append(msg)\n",
    "            else:\n",
    "                problems.append(msg)\n",
    "\n",
    "        return self.rephrase(\n",
    "            f\"\"\"\n",
    "- New files created: {files_created}\n",
    "- Existing files updated: {files_updated}\n",
    "- Problems encountered: {problems}\n",
    "\"\"\"\n",
    "        )\n",
    "\n",
    "    def search_code(self, query: str):\n",
    "        return self.github_api.search_code(query)\n",
    "\n",
    "<END OF FILE>\n",
    "Filepath: `autocoder/rag.py`\n",
    "File contents: from llama_index import Document, ServiceContext, VectorStoreIndex\n",
    "from llama_index.node_parser import CodeSplitter\n",
    "\n",
    "\n",
    "class RepositoryIndex:\n",
    "    def __init__(self, github_api, github_repository):\n",
    "        self.github_api = github_api\n",
    "\n",
    "        content = self.github_api.list_files_in_main_branch()\n",
    "        files = content.split(\"\\n\")[1:]\n",
    "        self.files = [file for file in files if \".py\" in file]\n",
    "\n",
    "        print(f\"Indexing codebase {github_repository}\")\n",
    "        self.documents = []\n",
    "        for i, file in enumerate(self.files):\n",
    "            print(f\"Indexing {file}\")\n",
    "            text = self.github_api.read_file(file)\n",
    "            loc = len([line for line in text.split(\"\\n\") if bool(line)])\n",
    "            # TODO: incorporate last_update_time and number_of_commits in metadata\n",
    "            self.documents.append(\n",
    "                Document(text=text, metadata={\"file\": file, \"loc\": loc})\n",
    "            )\n",
    "\n",
    "        code_splitter = CodeSplitter(language=\"python\", chunk_lines_overlap=25)\n",
    "        service_context = ServiceContext.from_defaults(text_splitter=code_splitter)\n",
    "        self.index = VectorStoreIndex.from_documents(\n",
    "            self.documents, service_context=service_context\n",
    "        )\n",
    "\n",
    "    def query(self, text: str):\n",
    "        query_engine = self.index.as_query_engine(\n",
    "            similarity_top_k=10, response_mode=\"no_text\"\n",
    "        )\n",
    "        response = query_engine.query(text)\n",
    "\n",
    "        nodes = response.source_nodes\n",
    "\n",
    "        # ranking by score and line of codes\n",
    "        nodes.sort(key=lambda n: n.score + n.metadata[\"loc\"], reverse=True)\n",
    "        return nodes\n",
    "\n",
    "<END OF FILE>\n",
    "Filepath: `notebooks/demo.ipynb`\n",
    "File contents: {\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 1,\n",
    "   \"id\": \"73541e6c-f4d8-4ed5-bfee-bbf10d1072e8\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"%load_ext autoreload\\n\",\n",
    "    \"%autoreload 2\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 2,\n",
    "   \"id\": \"4032d086-3eaf-48d3-8adf-5c350afc06d6\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"import os\\n\",\n",
    "    \"import sys\\n\",\n",
    "    \"\\n\",\n",
    "    \"parent_directory = os.path.abspath('..')\\n\",\n",
    "    \"sys.path.append(parent_directory)\\n\",\n",
    "    \"\\n\",\n",
    "    \"from actionweaver.llms import patch\\n\",\n",
    "    \"from langchain_community.utilities.github import GitHubAPIWrapper\\n\",\n",
    "    \"from langsmith.run_helpers import traceable\\n\",\n",
    "    \"\\n\",\n",
    "    \"from autocoder.bot import AutoCoder\\n\",\n",
    "    \"from autocoder.rag import RepositoryIndex\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 3,\n",
    "   \"id\": \"8cd3dc08-68d8-49a9-95c4-f1d5a1c178d6\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"name\": \"stdout\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"Indexing codebase TengHu/auto_coder\\n\",\n",
    "      \"Indexing autocoder/__init__.py\\n\",\n",
    "      \"Indexing autocoder/bot.py\\n\",\n",
    "      \"Indexing autocoder/pydantic_models.py\\n\",\n",
    "      \"Indexing autocoder/rag.py\\n\",\n",
    "      \"Indexing autocoder/telemetry.py\\n\",\n",
    "      \"Indexing main.py\\n\"\n",
    "     ]\n",
    "    }\n",
    "   ],\n",
    "   \"source\": [\n",
    "    \"github_repository = \\\"TengHu/auto_coder\\\"\\n\",\n",
    "    \"github_api = GitHubAPIWrapper(\\n\",\n",
    "    \"    github_repository=github_repository,\\n\",\n",
    "    \"    github_app_id=os.environ[\\\"GITHUB_APP_ID\\\"],\\n\",\n",
    "    \"    github_app_private_key=os.environ[\\\"GITHUB_APP_PRIVATE_KEY\\\"],\\n\",\n",
    "    \")\\n\",\n",
    "    \"\\n\",\n",
    "    \"index = RepositoryIndex(github_api, github_repository)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"id\": \"23d62a18-5426-450b-ba45-e63bbf2dc3c6\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": []\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 8,\n",
    "   \"id\": \"5137b4db-2208-4faf-a479-17076da18e9a\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"name\": \"stdout\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"[System] Branch 'aw_demo_bot_v8' created successfully, and set as current active branch.\\n\"\n",
    "     ]\n",
    "    }\n",
    "   ],\n",
    "   \"source\": [\n",
    "    \"auto_coder = AutoCoder(github_api, index)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 9,\n",
    "   \"id\": \"bad6fbc4-e66a-408e-867d-b617b6703275\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"name\": \"stdout\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"[\\\"- No new files were created.\\\\n- The following existing files received updates: \\\\n  - 'Updated file autocoder/bot.py' (mentioned multiple times, possibly indicating multiple update attempts)\\\\n  - 'Updated file autocoder/rag.py'\\\\n- Issues encountered included:\\\\n  - Updates to file content failed because the expected old content was not located. It might be beneficial to utilize the read_file action to retrieve the latest file contents before attempting updates. This issue was noted twice, suggesting repeated problems with updating file content.\\\"]\\n\"\n",
    "     ]\n",
    "    }\n",
    "   ],\n",
    "   \"source\": [\n",
    "    \"res = auto_coder(\\\"remove unused imports in autocoder/bot.py\\\")\\n\",\n",
    "    \"print(res)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 7,\n",
    "   \"id\": \"73751d5b-cfaa-4885-8445-746a551da29c\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"data\": {\n",
    "      \"text/plain\": [\n",
    "       \"'The pull request has been successfully created with the number 31. It includes the changes to reorder the imports in `autocoder/bot.py` to follow PEP 8 guidelines for better code readability and standardization.'\"\n",
    "      ]\n",
    "     },\n",
    "     \"execution_count\": 7,\n",
    "     \"metadata\": {},\n",
    "     \"output_type\": \"execute_result\"\n",
    "    }\n",
    "   ],\n",
    "   \"source\": [\n",
    "    \"auto_coder(\\\"create a pr\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 11,\n",
    "   \"id\": \"4d16a64d-de27-430f-b742-7c045af08813\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"nodes = index.query(\\\"AutoCoder\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 21,\n",
    "   \"id\": \"e5503aa5-b3af-400d-9d6a-79e05e12a372\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"nodes.sort(key=lambda n: n.score + n.metadata['loc'], reverse=True)\\n\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 20,\n",
    "   \"id\": \"cb77a698-4ea1-4cda-b0e8-56bf10bea428\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"data\": {\n",
    "      \"text/plain\": [\n",
    "       \"221\"\n",
    "      ]\n",
    "     },\n",
    "     \"execution_count\": 20,\n",
    "     \"metadata\": {},\n",
    "     \"output_type\": \"execute_result\"\n",
    "    }\n",
    "   ],\n",
    "   \"source\": [\n",
    "    \"nodes[-1].metadata['loc']\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 22,\n",
    "   \"id\": \"df5dbb4c-b934-48a1-9298-32a4f14bae59\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"res = auto_coder.search_code(\\\"AutoCoder\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 23,\n",
    "   \"id\": \"fc9d3d0e-232b-4f61-98a1-7eab421d7e37\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"name\": \"stdout\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"Showing top 4 of 4 results:\\n\",\n",
    "      \"Filepath: `autocoder/bot.py`\\n\",\n",
    "      \"File contents: import datetime\\n\",\n",
    "      \"import os\\n\",\n",
    "      \"import uuid\\n\",\n",
    "      \"from typing import List, Union\\n\",\n",
    "      \"\\n\",\n",
    "      \"from actionweaver import action\\n\",\n",
    "      \"from actionweaver.utils.tokens import TokenUsageTracker\\n\",\n",
    "      \"from langchain_community.utilities.github import GitHubAPIWrapper\\n\",\n",
    "      \"from langsmith.run_helpers import traceable\\n\",\n",
    "      \"from llama_index import Document, ServiceContext, VectorStoreIndex\\n\",\n",
    "      \"from llama_index.node_parser import CodeSplitter\\n\",\n",
    "      \"from openai import AzureOpenAI, OpenAI\\n\",\n",
    "      \"from pydantic import BaseModel, Field\\n\",\n",
    "      \"\\n\",\n",
    "      \"from autocoder.pydantic_models import create_context, create_tasks\\n\",\n",
    "      \"from autocoder.telemetry import trace_client\\n\",\n",
    "      \"\\n\",\n",
    "      \"assert os.environ[\\\"MODEL\\\"]\\n\",\n",
    "      \"MODEL = os.environ[\\\"MODEL\\\"]\\n\",\n",
    "      \"\\n\",\n",
    "      \"\\n\",\n",
    "      \"DIVIDING_LINE = \\\"\\\"\\\"\\n\",\n",
    "      \"###############\\n\",\n",
    "      \"This section is divider and not a part of the code.\\n\",\n",
    "      \"{input}\\n\",\n",
    "      \"#############\\n\",\n",
    "      \"\\n\",\n",
    "      \"\\\"\\\"\\\"\\n\",\n",
    "      \"\\n\",\n",
    "      \"\\n\",\n",
    "      \"class AutoCoder:\\n\",\n",
    "      \"    def __init__(self, github_api, index):\\n\",\n",
    "      \"        self.github_api = github_api\\n\",\n",
    "      \"\\n\",\n",
    "      \"        # self.client = trace_client(AzureOpenAI(\\n\",\n",
    "      \"        #     azure_endpoint = os.getenv(\\\"AZURE_OPENAI_ENDPOINT\\\"),\\n\",\n",
    "      \"        #     api_key=os.getenv(\\\"AZURE_OPENAI_KEY\\\"),\\n\",\n",
    "      \"        #     api_version=\\\"2023-10-01-preview\\\"\\n\",\n",
    "      \"        # ))\\n\",\n",
    "      \"        self.client = trace_client(OpenAI())\\n\",\n",
    "      \"        self.messages = [\\n\",\n",
    "      \"            {\\n\",\n",
    "      \"                \\\"role\\\": \\\"system\\\",\\n\",\n",
    "      \"                \\\"content\\\": \\\"You are a coding assistant, you have the capability to assist with code-related tasks and modify files.\\\",\\n\",\n",
    "      \"            },\\n\",\n",
    "      \"        ]\\n\",\n",
    "      \"        self.index = index\\n\",\n",
    "      \"\\n\",\n",
    "      \"        msg = self.create_branch(f\\\"aw_demo_bot\\\")\\n\",\n",
    "      \"        print(f\\\"[System] {msg}\\\")\\n\",\n",
    "      \"\\n\",\n",
    "      \"    def __call__(self, input: str):\\n\",\n",
    "      \"        self.messages.append({\\\"role\\\": \\\"user\\\", \\\"content\\\": input})\\n\",\n",
    "      \"\\n\",\n",
    "      \"        response = self.client.chat.completions.create(\\n\",\n",
    "      \"            model=MODEL,\\n\",\n",
    "      \"            messages=self.messages,\\n\",\n",
    "      \"            stream=False,\\n\",\n",
    "      \"            temperature=0.1,\\n\",\n",
    "      \"            actions=[\\n\",\n",
    "      \"                self.get_issues,\\n\",\n",
    "      \"                self.question_answer,\\n\",\n",
    "      \"                self.create_pull_request,\\n\",\n",
    "      \"                self.plan_code_change,\\n\",\n",
    "      \"            ],\\n\",\n",
    "      \"            orch={\\n\",\n",
    "      \"                self.plan_code_change.name: None,\\n\",\n",
    "      \"                self.create_pull_request.name: None,\\n\",\n",
    "      \"            },\\n\",\n",
    "      \"            token_usage_tracker=TokenUsageTracker(500),\\n\",\n",
    "      \"        )\\n\",\n",
    "      \"\\n\",\n",
    "      \"        content = \\\"\\\"\\n\",\n",
    "      \"        try:\\n\",\n",
    "      \"            content = response.choices[0].message.content\\n\",\n",
    "      \"        except:\\n\",\n",
    "      \"            content = str(response)\\n\",\n",
    "      \"        self.messages.append({\\\"role\\\": \\\"assistant\\\", \\\"content\\\": content})\\n\",\n",
    "      \"        return content\\n\",\n",
    "      \"\\n\",\n",
    "      \"    @traceable(run_type=\\\"tool\\\")\\n\",\n",
    "      \"    def gather_context(self, input, additional_params=None):\\n\",\n",
    "      \"        user_prompt = input\\n\",\n",
    "      \"\\n\",\n",
    "      \"        messages = [\\n\",\n",
    "      \"            # {\\n\",\n",
    "      \"            #     \\\"role\\\": \\\"system\\\",\\n\",\n",
    "      \"            #     \\\"content\\\": \\\"You are good at extract information from description\\\",\\n\",\n",
    "      \"            # },\\n\",\n",
    "      \"            {\\\"role\\\": \\\"user\\\", \\\"content\\\": f\\\"Description: {user_prompt}\\\"},\\n\",\n",
    "      \"        ]\\n\",\n",
    "      \"        context = create_context.invoke(\\n\",\n",
    "      \"            self.client,\\n\",\n",
    "      \"            messages=messages,\\n\",\n",
    "      \"            model=MODEL,\\n\",\n",
    "      \"            stream=False,\\n\",\n",
    "      \"            force=True,\\n\",\n",
    "      \"        )\\n\",\n",
    "      \"\\n\",\n",
    "      \"        if isinstance(context, list):\\n\",\n",
    "      \"            context = context[0]\\n\",\n",
    "      \"\\n\",\n",
    "      \"        index_response = \\\"\\\"\\n\",\n",
    "      \"        for query in context.semantic_queries + context.instructions:\\n\",\n",
    "      \"            nodes = self.index.query(query)\\n\",\n",
    "      \"            for node in nodes:\\n\",\n",
    "      \"                index_response = (\\n\",\n",
    "      \"                    index_response\\n\",\n",
    "      \"                    + DIVIDING_LINE.format(\\n\",\n",
    "      \"                        input=f\\\"Code Snippet From File: {node.metadata['file']}\\\"\\n\",\n",
    "      \"                    )\\n\",\n",
    "      \"                    + f\\\"{node.text}\\\"\\n\",\n",
    "      \"                )\\n\",\n",
    "      \"\\n\",\n",
    "      \"        file_response = self.read_files(context.files)\\n\",\n",
    "      \"\\n\",\n",
    "      \"        return (\\n\",\n",
    "      \"            \\\"CONTEXT FOR MAKING CODE MODIFICATIONS:\\\\n\\\"\\n\",\n",
    "      \"            + index_response\\n\",\n",
    "      \"            + \\\"\\\\n\\\"\\n\",\n",
    "      \"            + file_response\\n\",\n",
    "      \"        )\\n\",\n",
    "      \"\\n\",\n",
    "      \"    @action(name=\\\"QuestionAnswer\\\", decorators=[traceable(run_type=\\\"tool\\\")])\\n\",\n",
    "      \"    def question_answer(self, rewritten_query: str, keywords: List[str]):\\n\",\n",
    "      \"        \\\"\\\"\\\"Answer questions about the codebase\\\"\\\"\\\"\\n\",\n",
    "      \"\\n\",\n",
    "      \"        context = self.gather_context(description=\\\" \\\".join(keywords))\\n\",\n",
    "      \"\\n\",\n",
    "      \"        messages = [\\n\",\n",
    "      \"            {\\n\",\n",
    "      \"                \\\"role\\\": \\\"user\\\",\\n\",\n",
    "      \"                \\\"content\\\": f\\\"{context} \\\\n###########\\\\n Question: {rewritten_query}\\\",\\n\",\n",
    "      \"            }\\n\",\n",
    "      \"        ]\\n\",\n",
    "      \"        response = self.client.chat.completions.create(\\n\",\n",
    "      \"            model=MODEL,\\n\",\n",
    "      \"            messages=messages,\\n\",\n",
    "      \"            stream=False,\\n\",\n",
    "      \"            token_usage_tracker=TokenUsageTracker(500),\\n\",\n",
    "      \"        )\\n\",\n",
    "      \"        return response\\n\",\n",
    "      \"\\n\",\n",
    "      \"    @action(name=\\\"GetIssues\\\", decorators=[traceable(run_type=\\\"tool\\\")])\\n\",\n",
    "      \"    def get_issues(self):\\n\",\n",
    "      \"        \\\"\\\"\\\"\\n\",\n",
    "      \"        Get a list of issues from the GitHub repo.\\n\",\n",
    "      \"        \\\"\\\"\\\"\\n\",\n",
    "      \"        response = self.github_api.get_issues()\\n\",\n",
    "      \"        response = response.split(\\\"\\\\n\\\")\\n\",\n",
    "      \"        return eval(response[1]) if len(response) > 1 else []\\n\",\n",
    "      \"\\n\",\n",
    "      \"    @action(name=\\\"CreateGitBranch\\\", decorators=[traceable(run_type=\\\"tool\\\")])\\n\",\n",
    "      \"    def create_branch(self, branch: str):\\n\",\n",
    "      \"        \\\"\\\"\\\"\\n\",\n",
    "      \"        Create a new Git branch.\\n\",\n",
    "      \"        \\\"\\\"\\\"\\n\",\n",
    "      \"        return self.github_api.create_branch(branch)\\n\",\n",
    "      \"\\n\",\n",
    "      \"    @action(name=\\\"CreatePullRequest\\\", decorators=[traceable(run_type=\\\"tool\\\")])\\n\",\n",
    "      \"    def create_pull_request(self, title: str, description: str):\\n\",\n",
    "      \"        \\\"\\\"\\\"\\n\",\n",
    "      \"        Create a new Pull Request in a Git repository.\\n\",\n",
    "      \"\\n\",\n",
    "      \"        Args:\\n\",\n",
    "      \"            title (str): The title of the Pull Request.\\n\",\n",
    "      \"            description (str): The description of the Pull Request.\\n\",\n",
    "      \"        \\\"\\\"\\\"\\n\",\n",
    "      \"        return self.github_api.create_pull_request(pr_query=f\\\"{title}\\\\n {description}\\\")\\n\",\n",
    "      \"\\n\",\n",
    "      \"    @traceable(run_type=\\\"tool\\\")\\n\",\n",
    "      \"    def read_files(self, files: List[str]) -> List[str]:\\n\",\n",
    "      \"        \\\"\\\"\\\"\\n\",\n",
    "      \"        Read the content of multiple files in the GitHub repo\\n\",\n",
    "      \"\\n\",\n",
    "      \"        Args:\\n\",\n",
    "      \"            files (List[str]): A list of file paths to be read using the GitHub API.\\n\",\n",
    "      \"        \\\"\\\"\\\"\\n\",\n",
    "      \"        response = \\\"\\\"\\n\",\n",
    "      \"        for file in files:\\n\",\n",
    "      \"            api_response = self.github_api.read_file(file)\\n\",\n",
    "      \"            if f\\\"File not found `{file}`\\\" not in api_response:\\n\",\n",
    "      \"                response = (\\n\",\n",
    "      \"                    response\\n\",\n",
    "      \"                    + DIVIDING_LINE.format(input=f\\\"{file} full content:\\\")\\n\",\n",
    "      \"                    + f\\\"{self.github_api.read_file(file)}\\\\n\\\"\\n\",\n",
    "      \"                )\\n\",\n",
    "      \"        return response\\n\",\n",
    "      \"\\n\",\n",
    "      \"    def rephrase(self, input: str):\\n\",\n",
    "      \"        messages = [{\\\"role\\\": \\\"user\\\", \\\"content\\\": f\\\"{input}\\\\n####\\\\nRephrase\\\"}]\\n\",\n",
    "      \"        response = self.client.chat.completions.create(\\n\",\n",
    "      \"            model=MODEL,\\n\",\n",
    "      \"            messages=messages,\\n\",\n",
    "      \"            stream=False,\\n\",\n",
    "      \"            temperature=0.1,\\n\",\n",
    "      \"            token_usage_tracker=TokenUsageTracker(500),\\n\",\n",
    "      \"        )\\n\",\n",
    "      \"        content = \\\"\\\"\\n\",\n",
    "      \"        try:\\n\",\n",
    "      \"            content = response.choices[0].message.content\\n\",\n",
    "      \"        except:\\n\",\n",
    "      \"            content = str(response)\\n\",\n",
    "      \"        return content\\n\",\n",
    "      \"\\n\",\n",
    "      \"    @action(\\\"PlanCodeChange\\\", stop=True, decorators=[traceable(run_type=\\\"tool\\\")])\\n\",\n",
    "      \"    def plan_code_change(self, description: str):\\n\",\n",
    "      \"        \\\"\\\"\\\"\\n\",\n",
    "      \"        Plan code changes based on a given description.\\n\",\n",
    "      \"\\n\",\n",
    "      \"        This method is designed to handle various types of code alterations such as\\n\",\n",
    "      \"        inserting new code, refactoring existing code, replacing segments, or making\\n\",\n",
    "      \"        general modifications.\\n\",\n",
    "      \"        \\\"\\\"\\\"\\n\",\n",
    "      \"        context = self.gather_context(description=description)\\n\",\n",
    "      \"\\n\",\n",
    "      \"        user_prompt = f\\\"\\\"\\\"\\n\",\n",
    "      \"        {context}\\n\",\n",
    "      \"        {'#' * 20}\\n\",\n",
    "      \"        Description:\\n\",\n",
    "      \"        {description}\\\"\\\"\\\"\\n\",\n",
    "      \"\\n\",\n",
    "      \"        messages = [{\\\"role\\\": \\\"user\\\", \\\"content\\\": user_prompt}]\\n\",\n",
    "      \"        tasks = create_tasks.invoke(\\n\",\n",
    "      \"            self.client,\\n\",\n",
    "      \"            messages=messages,\\n\",\n",
    "      \"            temperature=0.1,\\n\",\n",
    "      \"            model=MODEL,\\n\",\n",
    "      \"            stream=False,\\n\",\n",
    "      \"            force=True,\\n\",\n",
    "      \"        )\\n\",\n",
    "      \"\\n\",\n",
    "      \"        if isinstance(tasks, list):\\n\",\n",
    "      \"            tasks = tasks[0]\\n\",\n",
    "      \"        messages = tasks.execute(self.client, self.github_api, context)\\n\",\n",
    "      \"\\n\",\n",
    "      \"        files_updated = []\\n\",\n",
    "      \"        files_created = []\\n\",\n",
    "      \"        problems = []\\n\",\n",
    "      \"        for msg in messages:\\n\",\n",
    "      \"            if \\\"Updated file\\\" in str(msg):\\n\",\n",
    "      \"                files_updated.append(msg)\\n\",\n",
    "      \"            elif \\\"Created file\\\" in str(msg):\\n\",\n",
    "      \"                files_created.append(msg)\\n\",\n",
    "      \"            else:\\n\",\n",
    "      \"                problems.append(msg)\\n\",\n",
    "      \"\\n\",\n",
    "      \"        return self.rephrase(\\n\",\n",
    "      \"            f\\\"\\\"\\\"\\n\",\n",
    "      \"- New files created: {files_created}\\n\",\n",
    "      \"- Existing files updated: {files_updated}\\n\",\n",
    "      \"- Problems encountered: {problems}\\n\",\n",
    "      \"\\\"\\\"\\\"\\n\",\n",
    "      \"        )\\n\",\n",
    "      \"\\n\",\n",
    "      \"    @action(name=\\\"SearchCode\\\", decorators=[traceable(run_type=\\\"tool\\\")])\\n\",\n",
    "      \"    def search_code(self, query: str):\\n\",\n",
    "      \"        return self.github_api.search_code(query)\\n\",\n",
    "      \"\\n\",\n",
    "      \"<END OF FILE>\\n\",\n",
    "      \"Filepath: `autocoder/telemetry.py`\\n\",\n",
    "      \"File contents: import os\\n\",\n",
    "      \"\\n\",\n",
    "      \"from actionweaver.llms import patch\\n\",\n",
    "      \"from langsmith.run_helpers import traceable\\n\",\n",
    "      \"\\n\",\n",
    "      \"os.environ[\\\"LANGCHAIN_ENDPOINT\\\"] = \\\"https://api.smith.langchain.com\\\"\\n\",\n",
    "      \"os.environ[\\\"LANGCHAIN_TRACING_V2\\\"] = \\\"true\\\"\\n\",\n",
    "      \"project_name = \\\"autocoder\\\"\\n\",\n",
    "      \"os.environ[\\\"LANGCHAIN_PROJECT\\\"] = project_name  # Optional: \\\"default\\\" is used if not set\\n\",\n",
    "      \"\\n\",\n",
    "      \"assert os.environ[\\\"LANGCHAIN_API_KEY\\\"]\\n\",\n",
    "      \"\\n\",\n",
    "      \"\\n\",\n",
    "      \"def trace_client(client):\\n\",\n",
    "      \"    client.chat.completions.create = traceable(name=\\\"llm_call\\\", run_type=\\\"llm\\\")(\\n\",\n",
    "      \"        client.chat.completions.create\\n\",\n",
    "      \"    )\\n\",\n",
    "      \"    client = patch(client)\\n\",\n",
    "      \"    client.chat.completions.create = traceable(\\n\",\n",
    "      \"        name=\\\"chat_completion_create\\\", run_type=\\\"llm\\\"\\n\",\n",
    "      \"    )(client.chat.completions.create)\\n\",\n",
    "      \"    return client\\n\",\n",
    "      \"\\n\",\n",
    "      \"<END OF FILE>\\n\",\n",
    "      \"Filepath: `main.py`\\n\",\n",
    "      \"File contents: import os\\n\",\n",
    "      \"\\n\",\n",
    "      \"from actionweaver.llms import patch\\n\",\n",
    "      \"from bot import AutoCoder\\n\",\n",
    "      \"from langchain_community.utilities.github import GitHubAPIWrapper\\n\",\n",
    "      \"from langsmith.run_helpers import traceable\\n\",\n",
    "      \"\\n\",\n",
    "      \"from autocoder.rag import RepositoryIndex\\n\",\n",
    "      \"\\n\",\n",
    "      \"assert os.environ[\\\"LANGCHAIN_API_KEY\\\"]\\n\",\n",
    "      \"assert os.environ[\\\"GITHUB_APP_ID\\\"]\\n\",\n",
    "      \"assert os.environ[\\\"GITHUB_APP_PRIVATE_KEY\\\"]\\n\",\n",
    "      \"\\n\",\n",
    "      \"# If use OpenAI API\\n\",\n",
    "      \"assert os.environ[\\\"OPENAI_API_KEY\\\"]\\n\",\n",
    "      \"\\n\",\n",
    "      \"\\n\",\n",
    "      \"os.environ[\\\"LANGCHAIN_ENDPOINT\\\"] = \\\"https://api.smith.langchain.com\\\"\\n\",\n",
    "      \"os.environ[\\\"LANGCHAIN_TRACING_V2\\\"] = \\\"true\\\"\\n\",\n",
    "      \"\\n\",\n",
    "      \"project_name = \\\"autocoder\\\"\\n\",\n",
    "      \"os.environ[\\\"LANGCHAIN_PROJECT\\\"] = project_name  # Optional: \\\"default\\\" is used if not set\\n\",\n",
    "      \"\\n\",\n",
    "      \"\\n\",\n",
    "      \"github_repository = \\\"TengHu/auto_coder\\\"\\n\",\n",
    "      \"github_api = GitHubAPIWrapper(\\n\",\n",
    "      \"    github_repository=github_repository,\\n\",\n",
    "      \"    github_app_id=os.environ[\\\"GITHUB_APP_ID\\\"],\\n\",\n",
    "      \"    github_app_private_key=os.environ[\\\"GITHUB_APP_PRIVATE_KEY\\\"],\\n\",\n",
    "      \")\\n\",\n",
    "      \"\\n\",\n",
    "      \"index = RepositoryIndex(github_api, github_repository)\\n\",\n",
    "      \"\\n\",\n",
    "      \"auto_coder = AutoCoder(github_api, None)\\n\",\n",
    "      \"res = auto_coder(\\\"What are the open issues?\\\")\\n\",\n",
    "      \"print(res)\\n\",\n",
    "      \"\\n\",\n",
    "      \"<END OF FILE>\\n\",\n",
    "      \"Filepath: `notebooks/demo.ipynb`\\n\",\n",
    "      \"File contents: {\\n\",\n",
    "      \" \\\"cells\\\": [\\n\",\n",
    "      \"  {\\n\",\n",
    "      \"   \\\"cell_type\\\": \\\"code\\\",\\n\",\n",
    "      \"   \\\"execution_count\\\": 1,\\n\",\n",
    "      \"   \\\"id\\\": \\\"73541e6c-f4d8-4ed5-bfee-bbf10d1072e8\\\",\\n\",\n",
    "      \"   \\\"metadata\\\": {},\\n\",\n",
    "      \"   \\\"outputs\\\": [],\\n\",\n",
    "      \"   \\\"source\\\": [\\n\",\n",
    "      \"    \\\"%load_ext autoreload\\\\n\\\",\\n\",\n",
    "      \"    \\\"%autoreload 2\\\"\\n\",\n",
    "      \"   ]\\n\",\n",
    "      \"  },\\n\",\n",
    "      \"  {\\n\",\n",
    "      \"   \\\"cell_type\\\": \\\"code\\\",\\n\",\n",
    "      \"   \\\"execution_count\\\": 2,\\n\",\n",
    "      \"   \\\"id\\\": \\\"4032d086-3eaf-48d3-8adf-5c350afc06d6\\\",\\n\",\n",
    "      \"   \\\"metadata\\\": {},\\n\",\n",
    "      \"   \\\"outputs\\\": [],\\n\",\n",
    "      \"   \\\"source\\\": [\\n\",\n",
    "      \"    \\\"import os\\\\n\\\",\\n\",\n",
    "      \"    \\\"import sys\\\\n\\\",\\n\",\n",
    "      \"    \\\"\\\\n\\\",\\n\",\n",
    "      \"    \\\"parent_directory = os.path.abspath('..')\\\\n\\\",\\n\",\n",
    "      \"    \\\"sys.path.append(parent_directory)\\\\n\\\",\\n\",\n",
    "      \"    \\\"\\\\n\\\",\\n\",\n",
    "      \"    \\\"from actionweaver.llms import patch\\\\n\\\",\\n\",\n",
    "      \"    \\\"from langchain_community.utilities.github import GitHubAPIWrapper\\\\n\\\",\\n\",\n",
    "      \"    \\\"from langsmith.run_helpers import traceable\\\\n\\\",\\n\",\n",
    "      \"    \\\"\\\\n\\\",\\n\",\n",
    "      \"    \\\"from autocoder.bot import AutoCoder\\\\n\\\",\\n\",\n",
    "      \"    \\\"from autocoder.rag import RepositoryIndex\\\"\\n\",\n",
    "      \"   ]\\n\",\n",
    "      \"  },\\n\",\n",
    "      \"  {\\n\",\n",
    "      \"   \\\"cell_type\\\": \\\"code\\\",\\n\",\n",
    "      \"   \\\"execution_count\\\": 3,\\n\",\n",
    "      \"   \\\"id\\\": \\\"8cd3dc08-68d8-49a9-95c4-f1d5a1c178d6\\\",\\n\",\n",
    "      \"   \\\"metadata\\\": {},\\n\",\n",
    "      \"   \\\"outputs\\\": [\\n\",\n",
    "      \"    {\\n\",\n",
    "      \"     \\\"name\\\": \\\"stdout\\\",\\n\",\n",
    "      \"     \\\"output_type\\\": \\\"stream\\\",\\n\",\n",
    "      \"     \\\"text\\\": [\\n\",\n",
    "      \"      \\\"Indexing codebase TengHu/auto_coder\\\\n\\\",\\n\",\n",
    "      \"      \\\"Indexing autocoder/bot.py\\\\n\\\",\\n\",\n",
    "      \"      \\\"Indexing autocoder/rag.py\\\\n\\\",\\n\",\n",
    "      \"      \\\"Indexing autocoder/telemetry.py\\\\n\\\",\\n\",\n",
    "      \"      \\\"Indexing main.py\\\\n\\\",\\n\",\n",
    "      \"      \\\"Indexing pydantic_models.py\\\\n\\\"\\n\",\n",
    "      \"     ]\\n\",\n",
    "      \"    }\\n\",\n",
    "      \"   ],\\n\",\n",
    "      \"   \\\"source\\\": [\\n\",\n",
    "      \"    \\\"github_repository = \\\\\\\"TengHu/auto_coder\\\\\\\"\\\\n\\\",\\n\",\n",
    "      \"    \\\"github_api = GitHubAPIWrapper(\\\\n\\\",\\n\",\n",
    "      \"    \\\"    github_repository=github_repository,\\\\n\\\",\\n\",\n",
    "      \"    \\\"    github_app_id=os.environ[\\\\\\\"GITHUB_APP_ID\\\\\\\"],\\\\n\\\",\\n\",\n",
    "      \"    \\\"    github_app_private_key=os.environ[\\\\\\\"GITHUB_APP_PRIVATE_KEY\\\\\\\"],\\\\n\\\",\\n\",\n",
    "      \"    \\\")\\\\n\\\",\\n\",\n",
    "      \"    \\\"\\\\n\\\",\\n\",\n",
    "      \"    \\\"index = RepositoryIndex(github_api, github_repository)\\\"\\n\",\n",
    "      \"   ]\\n\",\n",
    "      \"  },\\n\",\n",
    "      \"  {\\n\",\n",
    "      \"   \\\"cell_type\\\": \\\"code\\\",\\n\",\n",
    "      \"   \\\"execution_count\\\": null,\\n\",\n",
    "      \"   \\\"id\\\": \\\"23d62a18-5426-450b-ba45-e63bbf2dc3c6\\\",\\n\",\n",
    "      \"   \\\"metadata\\\": {},\\n\",\n",
    "      \"   \\\"outputs\\\": [],\\n\",\n",
    "      \"   \\\"source\\\": []\\n\",\n",
    "      \"  },\\n\",\n",
    "      \"  {\\n\",\n",
    "      \"   \\\"cell_type\\\": \\\"code\\\",\\n\",\n",
    "      \"   \\\"execution_count\\\": 4,\\n\",\n",
    "      \"   \\\"id\\\": \\\"5137b4db-2208-4faf-a479-17076da18e9a\\\",\\n\",\n",
    "      \"   \\\"metadata\\\": {},\\n\",\n",
    "      \"   \\\"outputs\\\": [\\n\",\n",
    "      \"    {\\n\",\n",
    "      \"     \\\"name\\\": \\\"stdout\\\",\\n\",\n",
    "      \"     \\\"output_type\\\": \\\"stream\\\",\\n\",\n",
    "      \"     \\\"text\\\": [\\n\",\n",
    "      \"      \\\"[System] Branch 'aw_demo_bot_v5' created successfully, and set as current active branch.\\\\n\\\"\\n\",\n",
    "      \"     ]\\n\",\n",
    "      \"    }\\n\",\n",
    "      \"   ],\\n\",\n",
    "      \"   \\\"source\\\": [\\n\",\n",
    "      \"    \\\"auto_coder = AutoCoder(github_api, index)\\\"\\n\",\n",
    "      \"   ]\\n\",\n",
    "      \"  },\\n\",\n",
    "      \"  {\\n\",\n",
    "      \"   \\\"cell_type\\\": \\\"code\\\",\\n\",\n",
    "      \"   \\\"execution_count\\\": 6,\\n\",\n",
    "      \"   \\\"id\\\": \\\"bad6fbc4-e66a-408e-867d-b617b6703275\\\",\\n\",\n",
    "      \"   \\\"metadata\\\": {},\\n\",\n",
    "      \"   \\\"outputs\\\": [\\n\",\n",
    "      \"    {\\n\",\n",
    "      \"     \\\"name\\\": \\\"stdout\\\",\\n\",\n",
    "      \"     \\\"output_type\\\": \\\"stream\\\",\\n\",\n",
    "      \"     \\\"text\\\": [\\n\",\n",
    "      \"      \\\"[\\\\\\\"Sure thing! Here's a more user-friendly version:\\\\\\\\n\\\\\\\\n- No new files have been added.\\\\\\\\n- We've made updates to the following files: 'telemetry.py' and 'bot.py' within the 'autocoder' folder.\\\\\\\\n- We didn't run into any issues along the way.\\\\\\\"]\\\\n\\\"\\n\",\n",
    "      \"     ]\\n\",\n",
    "      \"    }\\n\",\n",
    "      \"   ],\\n\",\n",
    "      \"   \\\"source\\\": [\\n\",\n",
    "      \"    \\\"res = auto_coder(\\\\\\\"Move trace_client function to bot.py.\\\\\\\")\\\\n\\\",\\n\",\n",
    "      \"    \\\"print(res)\\\"\\n\",\n",
    "      \"   ]\\n\",\n",
    "      \"  },\\n\",\n",
    "      \"  {\\n\",\n",
    "      \"   \\\"cell_type\\\": \\\"code\\\",\\n\",\n",
    "      \"   \\\"execution_count\\\": 7,\\n\",\n",
    "      \"   \\\"id\\\": \\\"73751d5b-cfaa-4885-8445-746a551da29c\\\",\\n\",\n",
    "      \"   \\\"metadata\\\": {},\\n\",\n",
    "      \"   \\\"outputs\\\": [\\n\",\n",
    "      \"    {\\n\",\n",
    "      \"     \\\"data\\\": {\\n\",\n",
    "      \"      \\\"text/plain\\\": [\\n\",\n",
    "      \"       \\\"'The pull request has been successfully created with the title \\\\\\\"Move trace_client Function to bot.py\\\\\\\" and the description \\\\\\\"This PR moves the trace_client function from its current location to bot.py for better organization and code structure.\\\\\\\" It is PR number 27.'\\\"\\n\",\n",
    "      \"      ]\\n\",\n",
    "      \"     },\\n\",\n",
    "      \"     \\\"execution_count\\\": 7,\\n\",\n",
    "      \"     \\\"metadata\\\": {},\\n\",\n",
    "      \"     \\\"output_type\\\": \\\"execute_result\\\"\\n\",\n",
    "      \"    }\\n\",\n",
    "      \"   ],\\n\",\n",
    "      \"   \\\"source\\\": [\\n\",\n",
    "      \"    \\\"auto_coder(\\\\\\\"create a pr\\\\\\\")\\\"\\n\",\n",
    "      \"   ]\\n\",\n",
    "      \"  },\\n\",\n",
    "      \"  {\\n\",\n",
    "      \"   \\\"cell_type\\\": \\\"code\\\",\\n\",\n",
    "      \"   \\\"execution_count\\\": null,\\n\",\n",
    "      \"   \\\"id\\\": \\\"4d16a64d-de27-430f-b742-7c045af08813\\\",\\n\",\n",
    "      \"   \\\"metadata\\\": {},\\n\",\n",
    "      \"   \\\"outputs\\\": [],\\n\",\n",
    "      \"   \\\"source\\\": []\\n\",\n",
    "      \"  },\\n\",\n",
    "      \"  {\\n\",\n",
    "      \"   \\\"cell_type\\\": \\\"code\\\",\\n\",\n",
    "      \"   \\\"execution_count\\\": null,\\n\",\n",
    "      \"   \\\"id\\\": \\\"e5503aa5-b3af-400d-9d6a-79e05e12a372\\\",\\n\",\n",
    "      \"   \\\"metadata\\\": {},\\n\",\n",
    "      \"   \\\"outputs\\\": [],\\n\",\n",
    "      \"   \\\"source\\\": []\\n\",\n",
    "      \"  },\\n\",\n",
    "      \"  {\\n\",\n",
    "      \"   \\\"cell_type\\\": \\\"code\\\",\\n\",\n",
    "      \"   \\\"execution_count\\\": 29,\\n\",\n",
    "      \"   \\\"id\\\": \\\"26a71e4f-054c-46d7-8a43-66b07fed9971\\\",\\n\",\n",
    "      \"   \\\"metadata\\\": {},\\n\",\n",
    "      \"   \\\"outputs\\\": [],\\n\",\n",
    "      \"   \\\"source\\\": [\\n\",\n",
    "      \"    \\\"from openai.types.chat.chat_completion_message import ChatCompletionMessage\\\\n\\\",\\n\",\n",
    "      \"    \\\"from openai.types.chat.chat_completion_message_tool_call import (\\\\n\\\",\\n\",\n",
    "      \"    \\\"    ChatCompletionMessageToolCall,\\\\n\\\",\\n\",\n",
    "      \"    \\\"Function\\\\n\\\",\\n\",\n",
    "      \"    \\\")\\\\n\\\",\\n\",\n",
    "      \"    \\\"messages = [{'role': 'system',\\\\n\\\",\\n\",\n",
    "      \"    \\\"  'content': 'You are a coding assistant, you have the capability to assist with code-related tasks and modify files.'},\\\\n\\\",\\n\",\n",
    "      \"    \\\" {'role': 'user', 'content': 'Move trace_client function to bot.py.'},\\\\n\\\",\\n\",\n",
    "      \"    \\\" ChatCompletionMessage(content=None, role='assistant', tool_calls=[ChatCompletionMessageToolCall(id='call_9f2agXdE5nnUl1X04XkYHjeQ', function=Function(arguments='{\\\\\\\"description\\\\\\\":\\\\\\\"Move the \\\\\\\\'trace_client\\\\\\\\' function from its current location to the \\\\\\\\'bot.py\\\\\\\\' file.\\\\\\\"}', name='PlanCodeChange'), type='function')]),\\\\n\\\",\\n\",\n",
    "      \"    \\\" {'tool_call_id': 'call_9f2agXdE5nnUl1X04XkYHjeQ',\\\\n\\\",\\n\",\n",
    "      \"    \\\"  'role': 'tool',\\\\n\\\",\\n\",\n",
    "      \"    \\\"  'name': 'PlanCodeChange',\\\\n\\\",\\n\",\n",
    "      \"    \\\"  'content': \\\\\\\"- New files created: []\\\\\\\\n        - Existing files updated: [['Updated file autocoder/bot.py', 'Updated file autocoder/telemetry.py']]\\\\\\\\n        - Problems encountered: []\\\\\\\\n        ###\\\\\\\\n    Ignore others,    Make the previous message more user-friendly\\\\\\\\n        \\\\\\\"}\\\\n\\\",\\n\",\n",
    "      \"    \\\"           ]\\\"\\n\",\n",
    "      \"   ]\\n\",\n",
    "      \"  },\\n\",\n",
    "      \"  {\\n\",\n",
    "      \"   \\\"cell_type\\\": \\\"code\\\",\\n\",\n",
    "      \"   \\\"execution_count\\\": 30,\\n\",\n",
    "      \"   \\\"id\\\": \\\"a1db6eea-8727-4b79-b971-217875e64fc4\\\",\\n\",\n",
    "      \"   \\\"metadata\\\": {},\\n\",\n",
    "      \"   \\\"outputs\\\": [],\\n\",\n",
    "      \"   \\\"source\\\": [\\n\",\n",
    "      \"    \\\"from openai import OpenAI\\\\n\\\",\\n\",\n",
    "      \"    \\\"\\\\n\\\",\\n\",\n",
    "      \"    \\\"\\\\n\\\",\\n\",\n",
    "      \"    \\\"client = OpenAI()\\\\n\\\",\\n\",\n",
    "      \"    \\\"response = client.chat.completions.create(\\\\n\\\",\\n\",\n",
    "      \"    \\\"            model=\\\\\\\"gpt-4-1106-preview\\\\\\\",\\\\n\\\",\\n\",\n",
    "      \"    \\\"            messages=messages,\\\\n\\\",\\n\",\n",
    "      \"    \\\"            stream=False,\\\\n\\\",\\n\",\n",
    "      \"    \\\"        )\\\"\\n\",\n",
    "      \"   ]\\n\",\n",
    "      \"  },\\n\",\n",
    "      \"  {\\n\",\n",
    "      \"   \\\"cell_type\\\": \\\"code\\\",\\n\",\n",
    "      \"   \\\"execution_count\\\": 31,\\n\",\n",
    "      \"   \\\"id\\\": \\\"6933b5be-f2cb-42c8-8f10-e1ce1f89761e\\\",\\n\",\n",
    "      \"   \\\"metadata\\\": {},\\n\",\n",
    "      \"   \\\"outputs\\\": [\\n\",\n",
    "      \"    {\\n\",\n",
    "      \"     \\\"name\\\": \\\"stdout\\\",\\n\",\n",
    "      \"     \\\"output_type\\\": \\\"stream\\\",\\n\",\n",
    "      \"     \\\"text\\\": [\\n\",\n",
    "      \"      \\\"ChatCompletion(id='chatcmpl-8h2sHwJwIR8SOkWxw2ypBGd80Uyom', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='I can assist you with moving the `trace_client` function to `bot.py`, but I need access to the source code or need to know where the current `trace_client` function is located. Can you provide the current code file that contains the `trace_client` function or tell me where to find it?', role='assistant', function_call=None, tool_calls=None))], created=1705269845, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_168383a679', usage=CompletionUsage(completion_tokens=63, prompt_tokens=135, total_tokens=198))\\\\n\\\"\\n\",\n",
    "      \"     ]\\n\",\n",
    "      \"    }\\n\",\n",
    "      \"   ],\\n\",\n",
    "      \"   \\\"source\\\": [\\n\",\n",
    "      \"    \\\"print (response)\\\"\\n\",\n",
    "      \"   ]\\n\",\n",
    "      \"  },\\n\",\n",
    "      \"  {\\n\",\n",
    "      \"   \\\"cell_type\\\": \\\"code\\\",\\n\",\n",
    "      \"   \\\"execution_count\\\": 32,\\n\",\n",
    "      \"   \\\"id\\\": \\\"09cb5b10-eda9-46e0-994d-60b2c5f86fb7\\\",\\n\",\n",
    "      \"   \\\"metadata\\\": {},\\n\",\n",
    "      \"   \\\"outputs\\\": [\\n\",\n",
    "      \"    {\\n\",\n",
    "      \"     \\\"name\\\": \\\"stdout\\\",\\n\",\n",
    "      \"     \\\"output_type\\\": \\\"stream\\\",\\n\",\n",
    "      \"     \\\"text\\\": [\\n\",\n",
    "      \"      \\\"I can assist you with moving the `trace_client` function to `bot.py`, but I need access to the source code or need to know where the current `trace_client` function is located. Can you provide the current code file that contains the `trace_client` function or tell me where to find it?\\\\n\\\"\\n\",\n",
    "      \"     ]\\n\",\n",
    "      \"    }\\n\",\n",
    "      \"   ],\\n\",\n",
    "      \"   \\\"source\\\": [\\n\",\n",
    "      \"    \\\"print (response.choices[0].message.content)\\\"\\n\",\n",
    "      \"   ]\\n\",\n",
    "      \"  },\\n\",\n",
    "      \"  {\\n\",\n",
    "      \"   \\\"cell_type\\\": \\\"code\\\",\\n\",\n",
    "      \"   \\\"execution_count\\\": 17,\\n\",\n",
    "      \"   \\\"id\\\": \\\"50c37b99-db67-4367-8771-a284e4dfab57\\\",\\n\",\n",
    "      \"   \\\"metadata\\\": {},\\n\",\n",
    "      \"   \\\"outputs\\\": [\\n\",\n",
    "      \"    {\\n\",\n",
    "      \"     \\\"name\\\": \\\"stdout\\\",\\n\",\n",
    "      \"     \\\"output_type\\\": \\\"stream\\\",\\n\",\n",
    "      \"     \\\"text\\\": [\\n\",\n",
    "      \"      \\\"You are a coding assistant, you have the capability to assist with code-related tasks and modify files.\\\\n\\\"\\n\",\n",
    "      \"     ]\\n\",\n",
    "      \"    }\\n\",\n",
    "      \"   ],\\n\",\n",
    "      \"   \\\"source\\\": [\\n\",\n",
    "      \"    \\\"print (messages[0]['content'])\\\"\\n\",\n",
    "      \"   ]\\n\",\n",
    "      \"  },\\n\",\n",
    "      \"  {\\n\",\n",
    "      \"   \\\"cell_type\\\": \\\"code\\\",\\n\",\n",
    "      \"   \\\"execution_count\\\": 18,\\n\",\n",
    "      \"   \\\"id\\\": \\\"df5b7a06-951b-4cc2-b7d2-cbbc864410b2\\\",\\n\",\n",
    "      \"   \\\"metadata\\\": {},\\n\",\n",
    "      \"   \\\"outputs\\\": [\\n\",\n",
    "      \"    {\\n\",\n",
    "      \"     \\\"data\\\": {\\n\",\n",
    "      \"      \\\"text/plain\\\": [\\n\",\n",
    "      \"       \\\"[{'role': 'system',\\\\n\\\",\\n\",\n",
    "      \"       \\\"  'content': 'You are a coding assistant, you have the capability to assist with code-related tasks and modify files.'},\\\\n\\\",\\n\",\n",
    "      \"       \\\" {'role': 'user', 'content': 'Move trace_client function to bot.py.'},\\\\n\\\",\\n\",\n",
    "      \"       \\\" ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_9f2agXdE5nnUl1X04XkYHjeQ', function=Function(arguments='{\\\\\\\"description\\\\\\\":\\\\\\\"Move the \\\\\\\\'trace_client\\\\\\\\' function from its current location to the \\\\\\\\'bot.py\\\\\\\\' file.\\\\\\\"}', name='PlanCodeChange'), type='function')]),\\\\n\\\",\\n\",\n",
    "      \"       \\\" {'tool_call_id': 'call_9f2agXdE5nnUl1X04XkYHjeQ',\\\\n\\\",\\n\",\n",
    "      \"       \\\"  'role': 'tool',\\\\n\\\",\\n\",\n",
    "      \"       \\\"  'name': 'PlanCodeChange',\\\\n\\\",\\n\",\n",
    "      \"       \\\"  'content': \\\\\\\"I've read code and attempted to create code changes. The outcome of these code changes is as follows:\\\\\\\\n        - New files created: []\\\\\\\\n        - Existing files updated: [['Updated file autocoder/bot.py', 'Updated file autocoder/telemetry.py']]\\\\\\\\n        - Problems encountered: []\\\\\\\\n        ###\\\\\\\\n        Make the previous message more user-friendly\\\\\\\\n        \\\\\\\"}]\\\"\\n\",\n",
    "      \"      ]\\n\",\n",
    "      \"     },\\n\",\n",
    "      \"     \\\"execution_count\\\": 18,\\n\",\n",
    "      \"     \\\"metadata\\\": {},\\n\",\n",
    "      \"     \\\"output_type\\\": \\\"execute_result\\\"\\n\",\n",
    "      \"    }\\n\",\n",
    "      \"   ],\\n\",\n",
    "      \"   \\\"source\\\": [\\n\",\n",
    "      \"    \\\"messages\\\"\\n\",\n",
    "      \"   ]\\n\",\n",
    "      \"  },\\n\",\n",
    "      \"  {\\n\",\n",
    "      \"   \\\"cell_type\\\": \\\"code\\\",\\n\",\n",
    "      \"   \\\"execution_count\\\": null,\\n\",\n",
    "      \"   \\\"id\\\": \\\"2939b91a-fe15-4338-a52a-d4a7da7a1aca\\\",\\n\",\n",
    "      \"   \\\"metadata\\\": {},\\n\",\n",
    "      \"   \\\"outputs\\\": [],\\n\",\n",
    "      \"   \\\"source\\\": []\\n\",\n",
    "      \"  },\\n\",\n",
    "      \"  {\\n\",\n",
    "      \"   \\\"cell_type\\\": \\\"code\\\",\\n\",\n",
    "      \"   \\\"execution_count\\\": null,\\n\",\n",
    "      \"   \\\"id\\\": \\\"412d9f50-be8d-4f9c-b166-59ba5f876748\\\",\\n\",\n",
    "      \"   \\\"metadata\\\": {},\\n\",\n",
    "      \"   \\\"outputs\\\": [],\\n\",\n",
    "      \"   \\\"source\\\": []\\n\",\n",
    "      \"  },\\n\",\n",
    "      \"  {\\n\",\n",
    "      \"   \\\"cell_type\\\": \\\"code\\\",\\n\",\n",
    "      \"   \\\"execution_count\\\": null,\\n\",\n",
    "      \"   \\\"id\\\": \\\"dcf75302-039f-44d8-a7da-791176d6db85\\\",\\n\",\n",
    "      \"   \\\"metadata\\\": {},\\n\",\n",
    "      \"   \\\"outputs\\\": [],\\n\",\n",
    "      \"   \\\"source\\\": []\\n\",\n",
    "      \"  }\\n\",\n",
    "      \" ],\\n\",\n",
    "      \" \\\"metadata\\\": {\\n\",\n",
    "      \"  \\\"kernelspec\\\": {\\n\",\n",
    "      \"   \\\"display_name\\\": \\\"Python 3 (ipykernel)\\\",\\n\",\n",
    "      \"   \\\"language\\\": \\\"python\\\",\\n\",\n",
    "      \"   \\\"name\\\": \\\"python3\\\"\\n\",\n",
    "      \"  },\\n\",\n",
    "      \"  \\\"language_info\\\": {\\n\",\n",
    "      \"   \\\"codemirror_mode\\\": {\\n\",\n",
    "      \"    \\\"name\\\": \\\"ipython\\\",\\n\",\n",
    "      \"    \\\"version\\\": 3\\n\",\n",
    "      \"   },\\n\",\n",
    "      \"   \\\"file_extension\\\": \\\".py\\\",\\n\",\n",
    "      \"   \\\"mimetype\\\": \\\"text/x-python\\\",\\n\",\n",
    "      \"   \\\"name\\\": \\\"python\\\",\\n\",\n",
    "      \"   \\\"nbconvert_exporter\\\": \\\"python\\\",\\n\",\n",
    "      \"   \\\"pygments_lexer\\\": \\\"ipython3\\\",\\n\",\n",
    "      \"   \\\"version\\\": \\\"3.9.18\\\"\\n\",\n",
    "      \"  }\\n\",\n",
    "      \" },\\n\",\n",
    "      \" \\\"nbformat\\\": 4,\\n\",\n",
    "      \" \\\"nbformat_minor\\\": 5\\n\",\n",
    "      \"}\\n\",\n",
    "      \"\\n\",\n",
    "      \"<END OF FILE>\\n\"\n",
    "     ]\n",
    "    }\n",
    "   ],\n",
    "   \"source\": [\n",
    "    \"print (res)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 29,\n",
    "   \"id\": \"26a71e4f-054c-46d7-8a43-66b07fed9971\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"from openai.types.chat.chat_completion_message import ChatCompletionMessage\\n\",\n",
    "    \"from openai.types.chat.chat_completion_message_tool_call import (\\n\",\n",
    "    \"    ChatCompletionMessageToolCall,\\n\",\n",
    "    \"Function\\n\",\n",
    "    \")\\n\",\n",
    "    \"messages = [{'role': 'system',\\n\",\n",
    "    \"  'content': 'You are a coding assistant, you have the capability to assist with code-related tasks and modify files.'},\\n\",\n",
    "    \" {'role': 'user', 'content': 'Move trace_client function to bot.py.'},\\n\",\n",
    "    \" ChatCompletionMessage(content=None, role='assistant', tool_calls=[ChatCompletionMessageToolCall(id='call_9f2agXdE5nnUl1X04XkYHjeQ', function=Function(arguments='{\\\"description\\\":\\\"Move the \\\\'trace_client\\\\' function from its current location to the \\\\'bot.py\\\\' file.\\\"}', name='PlanCodeChange'), type='function')]),\\n\",\n",
    "    \" {'tool_call_id': 'call_9f2agXdE5nnUl1X04XkYHjeQ',\\n\",\n",
    "    \"  'role': 'tool',\\n\",\n",
    "    \"  'name': 'PlanCodeChange',\\n\",\n",
    "    \"  'content': \\\"- New files created: []\\\\n        - Existing files updated: [['Updated file autocoder/bot.py', 'Updated file autocoder/telemetry.py']]\\\\n        - Problems encountered: []\\\\n        ###\\\\n    Ignore others,    Make the previous message more user-friendly\\\\n        \\\"}\\n\",\n",
    "    \"           ]\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 30,\n",
    "   \"id\": \"a1db6eea-8727-4b79-b971-217875e64fc4\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"from openai import OpenAI\\n\",\n",
    "    \"\\n\",\n",
    "    \"\\n\",\n",
    "    \"client = OpenAI()\\n\",\n",
    "    \"response = client.chat.completions.create(\\n\",\n",
    "    \"            model=\\\"gpt-4-1106-preview\\\",\\n\",\n",
    "    \"            messages=messages,\\n\",\n",
    "    \"            stream=False,\\n\",\n",
    "    \"        )\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 31,\n",
    "   \"id\": \"6933b5be-f2cb-42c8-8f10-e1ce1f89761e\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"name\": \"stdout\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"ChatCompletion(id='chatcmpl-8h2sHwJwIR8SOkWxw2ypBGd80Uyom', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='I can assist you with moving the `trace_client` function to `bot.py`, but I need access to the source code or need to know where the current `trace_client` function is located. Can you provide the current code file that contains the `trace_client` function or tell me where to find it?', role='assistant', function_call=None, tool_calls=None))], created=1705269845, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_168383a679', usage=CompletionUsage(completion_tokens=63, prompt_tokens=135, total_tokens=198))\\n\"\n",
    "     ]\n",
    "    }\n",
    "   ],\n",
    "   \"source\": [\n",
    "    \"print (response)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 32,\n",
    "   \"id\": \"09cb5b10-eda9-46e0-994d-60b2c5f86fb7\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"name\": \"stdout\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"I can assist you with moving the `trace_client` function to `bot.py`, but I need access to the source code or need to know where the current `trace_client` function is located. Can you provide the current code file that contains the `trace_client` function or tell me where to find it?\\n\"\n",
    "     ]\n",
    "    }\n",
    "   ],\n",
    "   \"source\": [\n",
    "    \"print (response.choices[0].message.content)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 17,\n",
    "   \"id\": \"50c37b99-db67-4367-8771-a284e4dfab57\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"name\": \"stdout\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"You are a coding assistant, you have the capability to assist with code-related tasks and modify files.\\n\"\n",
    "     ]\n",
    "    }\n",
    "   ],\n",
    "   \"source\": [\n",
    "    \"print (messages[0]['content'])\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 18,\n",
    "   \"id\": \"df5b7a06-951b-4cc2-b7d2-cbbc864410b2\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"data\": {\n",
    "      \"text/plain\": [\n",
    "       \"[{'role': 'system',\\n\",\n",
    "       \"  'content': 'You are a coding assistant, you have the capability to assist with code-related tasks and modify files.'},\\n\",\n",
    "       \" {'role': 'user', 'content': 'Move trace_client function to bot.py.'},\\n\",\n",
    "       \" ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_9f2agXdE5nnUl1X04XkYHjeQ', function=Function(arguments='{\\\"description\\\":\\\"Move the \\\\'trace_client\\\\' function from its current location to the \\\\'bot.py\\\\' file.\\\"}', name='PlanCodeChange'), type='function')]),\\n\",\n",
    "       \" {'tool_call_id': 'call_9f2agXdE5nnUl1X04XkYHjeQ',\\n\",\n",
    "       \"  'role': 'tool',\\n\",\n",
    "       \"  'name': 'PlanCodeChange',\\n\",\n",
    "       \"  'content': \\\"I've read code and attempted to create code changes. The outcome of these code changes is as follows:\\\\n        - New files created: []\\\\n        - Existing files updated: [['Updated file autocoder/bot.py', 'Updated file autocoder/telemetry.py']]\\\\n        - Problems encountered: []\\\\n        ###\\\\n        Make the previous message more user-friendly\\\\n        \\\"}]\"\n",
    "      ]\n",
    "     },\n",
    "     \"execution_count\": 18,\n",
    "     \"metadata\": {},\n",
    "     \"output_type\": \"execute_result\"\n",
    "    }\n",
    "   ],\n",
    "   \"source\": [\n",
    "    \"messages\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"id\": \"2939b91a-fe15-4338-a52a-d4a7da7a1aca\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": []\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"id\": \"412d9f50-be8d-4f9c-b166-59ba5f876748\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": []\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"id\": \"dcf75302-039f-44d8-a7da-791176d6db85\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": []\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3 (ipykernel)\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"codemirror_mode\": {\n",
    "    \"name\": \"ipython\",\n",
    "    \"version\": 3\n",
    "   },\n",
    "   \"file_extension\": \".py\",\n",
    "   \"mimetype\": \"text/x-python\",\n",
    "   \"name\": \"python\",\n",
    "   \"nbconvert_exporter\": \"python\",\n",
    "   \"pygments_lexer\": \"ipython3\",\n",
    "   \"version\": \"3.9.18\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 5\n",
    "}\n",
    "\n",
    "<END OF FILE>\n",
    "####################\n",
    "User Instruction:\n",
    "Identify and remove any unused imports in the file autocoder/bot.py.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2939b91a-fe15-4338-a52a-d4a7da7a1aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autocoder.pydantic_models_v2 import create_implementation_plan\n",
    "messages = [{\"role\": \"user\", \"content\": user_prompt}]\n",
    "\n",
    "implementation_plan = create_implementation_plan.invoke(\n",
    "    auto_coder.client,\n",
    "    messages=messages,\n",
    "    temperature=1,\n",
    "    model=os.environ[\"MODEL\"],\n",
    "    stream=False,\n",
    "    force=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c11904e-43cc-4173-908f-9e5244150971",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[FileModification(file_path='autocoder/bot.py', instruction='Remove unused import statements')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "implementation_plan[0].file_modifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f9787ea-3f14-40ca-abba-d13cb143d1bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ImplementationPlan(chain_of_thought='To identify and remove any unused imports in autocoder/bot.py, we need to first determine which imports are not being used in the file. This can be accomplished by analyzing the content of bot.py to see which imported modules and objects are not referenced anywhere in the code. Once we identify the unused imports, we can create a plan to remove these lines from the file.\\n\\nThe specific steps are to:\\n1. Analyze the file autocoder/bot.py to find all the import statements.\\n2. Determine which imports are not used in the rest of the file.\\n3. Remove the lines containing the unused imports.\\n4. Test to ensure that the removal of the imports does not affect the functionality of the script.\\n', file_modifications=[FileModification(file_path='autocoder/bot.py', instruction='Remove unused import statements')], file_creations=[])]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "implementation_plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "551fca6a-f3c2-48d1-aa38-dcd502055ae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Represents a plan to implement a feature, a plan include file creation/modification operations.\n",
      "\n",
      "    Example:\n",
      "        plan = ImplementationPlan(\n",
      "            chain_of_thought=\"Plan to refactor existing code.\",\n",
      "            file_modifications=[\n",
      "                FileModification(\n",
      "                    \n",
      "                    blocks=[\n",
      "        Block(\n",
      "            step_by_step_instruction_rewrite_the_block=\"Refactor a method called `foo` that takes a parameter named `bar` and returns `bar`\",\n",
      "            start_newline_of_interested_block=\"def foo(bar):\",\n",
      "            end_newline_of_interested_block=\"return bar\"\n",
      "        )\n",
      "        ]\n",
      "                )\n",
      "            ],\n",
      "            file_creations=[\n",
      "                FileCreation(\n",
      "                    file_name=\"new_feature.py\",\n",
      "                    content=\"def new_function():\n",
      "    # Add new feature code here\",\n",
      "                )\n",
      "            ],\n",
      "        )\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "from autocoder.pydantic_models_v2 import ImplementationPlan\n",
    "print (ImplementationPlan.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "412d9f50-be8d-4f9c-b166-59ba5f876748",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import os'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "implementation_plan[0].file_modifications[0].blocks[0].find_block(user_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dcf75302-039f-44d8-a7da-791176d6db85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matching Substring: apple pe\n"
     ]
    }
   ],
   "source": [
    "import difflib\n",
    "\n",
    "# Sample strings for comparison\n",
    "string1 = \"apple pie\"\n",
    "string2 = \"apples and pears\"\n",
    "\n",
    "# Calculate matching blocks\n",
    "matcher = difflib.SequenceMatcher(None, string1, string2)\n",
    "matching_blocks = matcher.get_matching_blocks()\n",
    "\n",
    "# Extract matching substring\n",
    "matching_substring = \"\"\n",
    "for block in matching_blocks:\n",
    "    i, j, length = block\n",
    "    matching_substring += string1[i:i + length]\n",
    "\n",
    "print(f\"Matching Substring: {matching_substring}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b9815535-b07a-4ba3-89c9-fb6374dbab44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' are awesome animal catterpillar who like other humans but not other caterpilar'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_here[s[1].a: s[1].b + s[1].size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b7f3ecef-9c3b-4420-80fb-ce5121036905",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21782178217821782"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.ratio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e24e29-2df1-46c3-9fed-e60eeb76e965",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
