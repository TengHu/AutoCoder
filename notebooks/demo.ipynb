{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4ff3137-2bcd-4604-bdea-78006481339c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4032d086-3eaf-48d3-8adf-5c350afc06d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gpt-4-32k'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "parent_directory = os.path.abspath('..')\n",
    "sys.path.append(parent_directory)\n",
    "\n",
    "from openai import AzureOpenAI\n",
    "from llama_index.llms import AzureOpenAI as LlamaIndexAzureOpenAI\n",
    "from autocoder.telemetry import trace_client\n",
    "\n",
    "from actionweaver.llms import patch\n",
    "from langchain_community.utilities.github import GitHubAPIWrapper\n",
    "\n",
    "from autocoder.bot import AutoCoder\n",
    "from autocoder.index import RepositoryIndex\n",
    "from autocoder.codebase import Codebase\n",
    "\n",
    "os.environ[\"MODEL\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "02554390-6ccb-4da1-a163-c722a5cebdcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = trace_client(AzureOpenAI(\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_KEY\"),\n",
    "    api_version=\"2023-10-01-preview\",\n",
    "))\n",
    "\n",
    "llm_for_rag = LlamaIndexAzureOpenAI(\n",
    "    engine=os.environ[\"MODEL\"],\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_KEY\"),\n",
    "    api_version=\"2023-10-01-preview\",\n",
    "    use_azure_ad=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8cd3dc08-68d8-49a9-95c4-f1d5a1c178d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "github_repository = \"TengHu/AutoCoder\"\n",
    "github_api = GitHubAPIWrapper(\n",
    "    github_repository=github_repository,\n",
    "    github_app_id=os.environ[\"GITHUB_APP_ID\"],\n",
    "    github_app_private_key=os.environ[\"GITHUB_APP_PRIVATE_KEY\"],\n",
    ")\n",
    "codebase = Codebase(github_api)\n",
    "index = RepositoryIndex(github_repository, codebase, llm_for_rag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "cd099969-a66c-4054-8015-25b46fdbb364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m[DEBUG] \u001b[0mBranch 'demo_v8' created successfully, and set as current active branch.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Branch 'demo_v8' created successfully, and set as current active branch.\""
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto_coder = AutoCoder(index, codebase, llm, create_branch=False)\n",
    "auto_coder.create_branch(\"demo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "66c39ea4-5a13-4edf-9942-8e8474367b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = '''[Code Change] Optimize the code in `autocoder/telemetry.py`\n",
    "- refactor identity_decorator to be more compact\n",
    "- remove redundant code in traceable and trace_client'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "44e83542-1cb0-415a-9bde-94f04155bb97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m[DEBUG] \u001b[0mPlanning code change: Optimize the code in `autocoder/telemetry.py`\n",
      "- refactor identity_decorator to be more compact\n",
      "- remove redundant code in traceable and trace_client\n",
      "\u001b[92m[DEBUG] \u001b[0mImplementation plan created: Refactor the code in `autocoder/telemetry.py`, specifically the `identity_decorator`, `traceable` and `trace_client` functions. For `identity_decorator`, the function can be made more compact. For `traceable` and `trace_client`, redundant code should be removed.\n",
      "\u001b[96mautocoder/telemetry.py\u001b[0m:1. For `identity_decorator`, it's currently a function that takes any function as input and returns the same function. This can be simplified. \n",
      "2. In `traceable`, there is a check if `LANGCHAIN_API_KEY` is in the environment variables and applies a decorator accordingly. This is repeated in `trace_client` as well. This is redundant and can be removed from one of the places.\n",
      "\n",
      "\u001b[92m[DEBUG] \u001b[0mModifying file: autocoder/telemetry.py\n",
      "\u001b[92m[DEBUG] \u001b[0mCommitting code change to autocoder/telemetry.py\n",
      "  def identity_decorator(func):\n",
      "\u001b[32m+     return func\u001b[0m\n",
      "\u001b[31m-     def wrapper(*args, **kwargs):\u001b[0m\n",
      "\u001b[31m-         result = func(*args, **kwargs)\u001b[0m\n",
      "\u001b[31m-         return result\u001b[0m\n",
      "\u001b[31m- \u001b[0m\n",
      "\u001b[31m-     return wrapper\u001b[0m\n",
      "\u001b[92m[DEBUG] \u001b[0mCommitting code change to autocoder/telemetry.py\n",
      "  def traceable(*args, **kwargs):\n",
      "\u001b[31m-     if os.environ.get(\"LANGCHAIN_API_KEY\"):\u001b[0m\n",
      "\u001b[31m-         return _traceable(*args, **kwargs)\u001b[0m\n",
      "\u001b[32m+     return _traceable(*args, **kwargs)\u001b[0m\n",
      "\u001b[31m-     else:\u001b[0m\n",
      "\u001b[31m-         return identity_decorator\u001b[0m\n",
      "\u001b[92m[DEBUG] \u001b[0mCommitting code change to autocoder/telemetry.py\n",
      "  def trace_client(client):\n",
      "\u001b[31m-     if os.environ.get(\"LANGCHAIN_API_KEY\"):\u001b[0m\n",
      "\u001b[31m-         client.chat.completions.create = traceable(name=\"llm_call\", run_type=\"llm\")(\u001b[0m\n",
      "\u001b[32m+     client.chat.completions.create = traceable(name=\"llm_call\", run_type=\"llm\")(\u001b[0m\n",
      "\u001b[31m-             client.chat.completions.create\u001b[0m\n",
      "\u001b[32m+         client.chat.completions.create\u001b[0m\n",
      "\u001b[31m-         )\u001b[0m\n",
      "\u001b[32m+     )\u001b[0m\n",
      "\u001b[31m-         client = patch(client)\u001b[0m\n",
      "\u001b[32m+     client = patch(client)\u001b[0m\n",
      "\u001b[31m-         client.chat.completions.create = traceable(\u001b[0m\n",
      "\u001b[32m+     client.chat.completions.create = traceable(\u001b[0m\n",
      "\u001b[31m-             name=\"chat_completion_create\", run_type=\"llm\"\u001b[0m\n",
      "\u001b[32m+         name=\"chat_completion_create\", run_type=\"llm\"\u001b[0m\n",
      "\u001b[31m-         )(client.chat.completions.create)\u001b[0m\n",
      "\u001b[32m+     )(client.chat.completions.create)\u001b[0m\n",
      "\u001b[31m-         return client\u001b[0m\n",
      "\u001b[32m+     return client\u001b[0m\n",
      "\u001b[31m-     else:\u001b[0m\n",
      "\u001b[31m-         return client\u001b[0m\n",
      "The code in `autocoder/telemetry.py` has been optimized by making the `identity_decorator` more compact and eliminating unnecessary code in `traceable` and `trace_client`.\n"
     ]
    }
   ],
   "source": [
    "res = auto_coder(input)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a77c4c-a253-4f26-af14-47289a9916be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "c22b223a-e692-4293-8598-56ad04009f98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I have successfully created a new pull request with number 101.'"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto_coder(\"create PR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c26fa26-9f69-4921-b605-c73f810d612e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68800d75-5151-4a49-aa16-07ce0a85a88a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6cf836-0365-4739-9f9c-a3ed111a36ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
