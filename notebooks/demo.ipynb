{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4032d086-3eaf-48d3-8adf-5c350afc06d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gpt-4-1106-preview'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "parent_directory = os.path.abspath('..')\n",
    "sys.path.append(parent_directory)\n",
    "\n",
    "\n",
    "from actionweaver.llms import patch\n",
    "from langchain_community.utilities.github import GitHubAPIWrapper\n",
    "from langsmith.run_helpers import traceable\n",
    "\n",
    "from autocoder.bot import AutoCoder\n",
    "from autocoder.index import RepositoryIndex\n",
    "\n",
    "from autocoder.codebase import Codebase\n",
    "\n",
    "os.environ[\"MODEL\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8cd3dc08-68d8-49a9-95c4-f1d5a1c178d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RepositoryIndex] Indexing codebase TengHu/AutoCoder\n",
      "[RepositoryIndex] Reading autocoder/__init__.py\n",
      "[RepositoryIndex] Reading autocoder/bot.py\n",
      "[RepositoryIndex] Reading autocoder/codebase.py\n",
      "[RepositoryIndex] Reading autocoder/index.py\n",
      "[RepositoryIndex] Reading autocoder/pydantic_models/code_block_ops.py\n",
      "[RepositoryIndex] Reading autocoder/pydantic_models/context.py\n",
      "[RepositoryIndex] Reading autocoder/pydantic_models/file_ops.py\n",
      "[RepositoryIndex] Reading autocoder/telemetry.py\n",
      "[RepositoryIndex] Reading main.py\n"
     ]
    }
   ],
   "source": [
    "github_repository = \"TengHu/AutoCoder\"\n",
    "github_api = GitHubAPIWrapper(\n",
    "    github_repository=github_repository,\n",
    "    github_app_id=os.environ[\"GITHUB_APP_ID\"],\n",
    "    github_app_private_key=os.environ[\"GITHUB_APP_PRIVATE_KEY\"],\n",
    ")\n",
    "codebase = Codebase(github_api)\n",
    "index = RepositoryIndex(github_repository, codebase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd099969-a66c-4054-8015-25b46fdbb364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[System] Branch 'aw_demo_bot_v3' created successfully, and set as current active branch.\n"
     ]
    }
   ],
   "source": [
    "auto_coder = AutoCoder(index, codebase, create_branch=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "66c39ea4-5a13-4edf-9942-8e8474367b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = \"\"\"Create separate files for each class in autocoder/pydantic_models/file_ops.py\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "44e83542-1cb0-415a-9bde-94f04155bb97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The message indicates that the sender has made updates to a codebase in a branch named `aw_demo_bot_v3`. The updates include:\\n\\n- Creation of new files:\\n  - `autocoder/pydantic_models/file_operation.py`\\n  - `autocoder/pydantic_models/file_modification.py`\\n  - `autocoder/pydantic_models/file_creation.py`\\n\\n- Updates to existing files:\\n  - The file `autocoder/pydantic_models/file_ops.py` was updated three times.\\n\\nNo problems were encountered during the process. The sender is asking if there is anything else they can assist with.']\n"
     ]
    }
   ],
   "source": [
    "res = auto_coder(input)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f2004ec-842d-4886-b319-941aded910ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A pull request (PR number 81) has been successfully created, titled \"Switch to AzureOpenAI Client\". The PR updates the `autocoder/bot.py` to use the AzureOpenAI client instead of the OpenAI client for API interactions.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto_coder(\"create PR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22b223a-e692-4293-8598-56ad04009f98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c26fa26-9f69-4921-b605-c73f810d612e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2571194-d2fa-491d-a60c-529a444a2a18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67af88f9-99c3-4b86-a11b-5eb6c3b76bbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "528fdb6b-c997-4b4a-99a3-c46caed0c56c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        # self.client = trace_client(AzureOpenAI(\n",
      "        #     azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
      "        #     api_key=os.getenv(\"AZURE_OPENAI_KEY\"),\n",
      "        #     api_version=\"2023-10-01-preview\"\n"
     ]
    }
   ],
   "source": [
    "print ('\\n        # self.client = trace_client(AzureOpenAI(\\n        #     azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\\n        #     api_key=os.getenv(\"AZURE_OPENAI_KEY\"),\\n        #     api_version=\"2023-10-01-preview\"'\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2ea58fd9-9c63-4753-8591-5b8d62736fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.client = trace_client(AzureOpenAI(\n",
      "    azure_endpoint = os.getenv('AZURE_OPENAI_ENDPOINT'),\n",
      "    api_key=os.getenv('AZURE_OPENAI_KEY'),\n",
      "    api_version='2023-10-01-preview'\n",
      "))\n"
     ]
    }
   ],
   "source": [
    "print (\"self.client = trace_client(AzureOpenAI(\\n    azure_endpoint = os.getenv('AZURE_OPENAI_ENDPOINT'),\\n    api_key=os.getenv('AZURE_OPENAI_KEY'),\\n    api_version='2023-10-01-preview'\\n))\"\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "063a1a2d-9b0f-4393-85aa-9155ce8f2b6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# self.client = trace_client(AzureOpenAI(\n",
      "        #     azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
      "        #     api_key=os.getenv(\"AZURE_OPENAI_KEY\"),\n",
      "        #     api_version=\"2023-10-01-preview\"\n"
     ]
    }
   ],
   "source": [
    "print ('# self.client = trace_client(AzureOpenAI(\\n        #     azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\\n        #     api_key=os.getenv(\"AZURE_OPENAI_KEY\"),\\n        #     api_version=\"2023-10-01-preview\"'\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87d198a-17a4-437f-994b-7da2ce30b73f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fc1c0cac-1822-4af8-8d35-6f05bc44e13d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.client = trace_client(AzureOpenAI(\n",
      "    azure_endpoint = os.getenv('AZURE_OPENAI_ENDPOINT'),\n",
      "    api_key=os.getenv('AZURE_OPENAI_KEY'),\n",
      "    api_version='2023-10-01-preview'\n",
      "))\n"
     ]
    }
   ],
   "source": [
    "print (\"self.client = trace_client(AzureOpenAI(\\n    azure_endpoint = os.getenv('AZURE_OPENAI_ENDPOINT'),\\n    api_key=os.getenv('AZURE_OPENAI_KEY'),\\n    api_version='2023-10-01-preview'\\n))\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f8210a9-5311-4ea8-b6ea-9d0b1ae434a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        self.client = trace_client(AzureOpenAI(\n",
      "            azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
      "            api_key=os.getenv(\"AZURE_OPENAI_KEY\"),\n",
      "            api_version=\"2023-10-01-preview\"\n",
      "        ))\n"
     ]
    }
   ],
   "source": [
    "print (\"        self.client = trace_client(AzureOpenAI(\\n            azure_endpoint=os.getenv(\\\"AZURE_OPENAI_ENDPOINT\\\"),\\n            api_key=os.getenv(\\\"AZURE_OPENAI_KEY\\\"),\\n            api_version=\\\"2023-10-01-preview\\\"\\n        ))\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ece51c14-454a-4012-bbb7-af95275cbea0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gpt-4-1106-preview'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from autocoder.pydantic_models.code_block_ops import create_blocks\n",
    "os.environ[\"MODEL\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d0f73954-d533-4ec9-80dc-c0d3e764b18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = '''<context>:\n",
    "<snippet autocoder/bot.py start_line=0 end_line=70>\n",
    "0. import os\n",
    "1. from typing import List\n",
    "2. \n",
    "3. from actionweaver import action\n",
    "4. from actionweaver.utils.tokens import TokenUsageTracker\n",
    "5. from openai import OpenAI\n",
    "6. \n",
    "7. from autocoder.pydantic_models.context import create_context, gather_context\n",
    "8. from autocoder.pydantic_models.file_ops import create_implementation_plan\n",
    "9. from autocoder.telemetry import trace_client, traceable\n",
    "10. \n",
    "11. assert os.environ[\"MODEL\"]\n",
    "12. MODEL = os.environ[\"MODEL\"]\n",
    "13. \n",
    "14. \n",
    "15. class AutoCoder:\n",
    "16.     def __init__(self, github_api, index, codebase):\n",
    "17.         self.github_api = github_api\n",
    "18. \n",
    "19.         # self.client = trace_client(AzureOpenAI(\n",
    "20.         #     azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "21.         #     api_key=os.getenv(\"AZURE_OPENAI_KEY\"),\n",
    "22.         #     api_version=\"2023-10-01-preview\"\n",
    "23.         # ))\n",
    "24.         self.client = trace_client(OpenAI())\n",
    "25.         self.system_message = {\n",
    "26.             \"role\": \"system\",\n",
    "27.             \"content\": \"You are a coding assistant, you have the capability to assist with code-related tasks and modify files.\",\n",
    "28.         }\n",
    "29.         self.messages = [self.system_message]\n",
    "30.         self.index = index\n",
    "31.         self.codebase = codebase\n",
    "32. \n",
    "33.         msg = self.create_branch(f\"aw_demo_bot\")\n",
    "34.         print(f\"[System] {msg}\")\n",
    "35. \n",
    "36.     def __call__(self, input: str):\n",
    "37.         self.original_input = input\n",
    "38. \n",
    "39.         self.messages.append(\n",
    "40.             {\n",
    "41.                 \"role\": \"user\",\n",
    "42.                 \"content\": \"<user_query>\\n\" + input + \"\\n</user_query>\",\n",
    "43.             }\n",
    "44.         )\n",
    "45. \n",
    "46.         response = self.client.chat.completions.create(\n",
    "47.             model=MODEL,\n",
    "48.             messages=self.messages,\n",
    "49.             stream=False,\n",
    "50.             temperature=0.1,\n",
    "51.             actions=[\n",
    "52.                 self.get_issues,\n",
    "53.                 self.question_answer,\n",
    "54.                 self.create_pull_request,\n",
    "55.                 self.plan_code_change,\n",
    "56.             ],\n",
    "57.             orch={\n",
    "58.                 self.plan_code_change.name: self.summarize_changes,\n",
    "59.                 self.create_pull_request.name: None,\n",
    "60.             },\n",
    "61.             token_usage_tracker=TokenUsageTracker(500),\n",
    "62.         )\n",
    "63. \n",
    "64.         content = \"\"\n",
    "65.         try:\n",
    "66.             content = response.choices[0].message.content\n",
    "67.         except:\n",
    "68.             content = str(response)\n",
    "69.         self.messages.append({\"role\": \"assistant\", \"content\": content})\n",
    "70.         return content\n",
    "</snippet autocoder/bot.py>\n",
    "<snippet autocoder/bot.py start_line=15 end_line=70>\n",
    "15. class AutoCoder:\n",
    "16.     def __init__(self, github_api, index, codebase):\n",
    "17.         self.github_api = github_api\n",
    "18. \n",
    "19.         # self.client = trace_client(AzureOpenAI(\n",
    "20.         #     azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "21.         #     api_key=os.getenv(\"AZURE_OPENAI_KEY\"),\n",
    "22.         #     api_version=\"2023-10-01-preview\"\n",
    "23.         # ))\n",
    "24.         self.client = trace_client(OpenAI())\n",
    "25.         self.system_message = {\n",
    "26.             \"role\": \"system\",\n",
    "27.             \"content\": \"You are a coding assistant, you have the capability to assist with code-related tasks and modify files.\",\n",
    "28.         }\n",
    "29.         self.messages = [self.system_message]\n",
    "30.         self.index = index\n",
    "31.         self.codebase = codebase\n",
    "32. \n",
    "33.         msg = self.create_branch(f\"aw_demo_bot\")\n",
    "34.         print(f\"[System] {msg}\")\n",
    "35. \n",
    "36.     def __call__(self, input: str):\n",
    "37.         self.original_input = input\n",
    "38. \n",
    "39.         self.messages.append(\n",
    "40.             {\n",
    "41.                 \"role\": \"user\",\n",
    "42.                 \"content\": \"<user_query>\\n\" + input + \"\\n</user_query>\",\n",
    "43.             }\n",
    "44.         )\n",
    "45. \n",
    "46.         response = self.client.chat.completions.create(\n",
    "47.             model=MODEL,\n",
    "48.             messages=self.messages,\n",
    "49.             stream=False,\n",
    "50.             temperature=0.1,\n",
    "51.             actions=[\n",
    "52.                 self.get_issues,\n",
    "53.                 self.question_answer,\n",
    "54.                 self.create_pull_request,\n",
    "55.                 self.plan_code_change,\n",
    "56.             ],\n",
    "57.             orch={\n",
    "58.                 self.plan_code_change.name: self.summarize_changes,\n",
    "59.                 self.create_pull_request.name: None,\n",
    "60.             },\n",
    "61.             token_usage_tracker=TokenUsageTracker(500),\n",
    "62.         )\n",
    "63. \n",
    "64.         content = \"\"\n",
    "65.         try:\n",
    "66.             content = response.choices[0].message.content\n",
    "67.         except:\n",
    "68.             content = str(response)\n",
    "69.         self.messages.append({\"role\": \"assistant\", \"content\": content})\n",
    "70.         return content\n",
    "</snippet autocoder/bot.py>\n",
    "<snippet autocoder/codebase.py start_line=4 end_line=42>\n",
    "4.     def __init__(self, github_api):\n",
    "5.         self.github_api = github_api\n",
    "6.         self.file2code = {}\n",
    "7. \n",
    "8.     def list_files_in_bot_branch(self):\n",
    "9.         content = self.github_api.list_files_in_bot_branch()\n",
    "10.         files = content.split(\"\\n\")[1:]\n",
    "11.         return files\n",
    "12. \n",
    "13.     def clear_cache(self):\n",
    "14.         self.file2code = {}\n",
    "15. \n",
    "16.     def read_file(self, filepath):\n",
    "17.         response = None\n",
    "18. \n",
    "19.         if filepath not in self.file2code:\n",
    "20.             response = self.read_file_wrapper(filepath)\n",
    "21.             if f\"File not found `{filepath}`\" in response:\n",
    "22.                 # raise Exception(f\"{filepath} doesn't exist\")\n",
    "23.                 return None\n",
    "24.             self.file2code[filepath] = response\n",
    "25. \n",
    "26.         response = self.file2code[filepath]\n",
    "27. \n",
    "28.         return response\n",
    "29. \n",
    "30.     def read_file_wrapper(self, filepath):\n",
    "31.         response = self.github_api.read_file(filepath)\n",
    "32. \n",
    "33.         return response\n",
    "34. \n",
    "35.     def read_files(self, files: List[str]) -> List[str]:\n",
    "36.         response = {}\n",
    "37.         for file in files:\n",
    "38.             read_file_response = self.read_file(file)\n",
    "39. \n",
    "40.             if read_file_response:\n",
    "41.                 response[file] = read_file_response\n",
    "42.         return response\n",
    "</snippet autocoder/codebase.py>\n",
    "<snippet autocoder/index.py start_line=27 end_line=68>\n",
    "27.     def __init__(self, github_api, github_repository, codebase):\n",
    "28.         self.github_api = github_api\n",
    "29.         self.codebase = codebase\n",
    "30.         self.github_repository = github_repository\n",
    "31. \n",
    "32.         self.llm = OpenAI(model=\"gpt-3.5-turbo-16k\", temperature=0.1, max_tokens=256)\n",
    "33.         self.embed_model = OpenAIEmbedding(model=\"text-embedding-ada-002\")\n",
    "34.         self.setup()\n",
    "35. \n",
    "36.     def setup(self):\n",
    "37.         files = self.codebase.list_files_in_bot_branch()\n",
    "38.         self.files = [file for file in files if \".py\" in file]\n",
    "39. \n",
    "40.         print(f\"[RepositoryIndex] Indexing codebase {self.github_repository}\")\n",
    "41.         self.documents = []\n",
    "42.         for i, file in enumerate(self.files):\n",
    "43.             print(f\"[RepositoryIndex] Reading {file}\")\n",
    "44.             text = self.codebase.read_file(file)\n",
    "45.             self.documents.append(Document(text=text, metadata={\"file\": file}))\n",
    "46. \n",
    "47.         code_splitter = CodeSplitter(\n",
    "48.             language=\"python\", chunk_lines=40, chunk_lines_overlap=25, max_chars=2000\n",
    "49.         )\n",
    "50.         self.service_context = ServiceContext.from_defaults(\n",
    "51.             llm=self.llm, embed_model=self.embed_model, text_splitter=code_splitter\n",
    "52.         )\n",
    "53.         self.index = VectorStoreIndex.from_documents(\n",
    "54.             self.documents, service_context=self.service_context\n",
    "55.         )\n",
    "56. \n",
    "57.     def _retrieve_with_transform(self, query_bundle: QueryBundle):\n",
    "58.         base_retriever = self.index.as_retriever(\n",
    "59.             similarity_top_k=50, response_mode=\"no_text\"\n",
    "60.         )\n",
    "61. \n",
    "62.         # Use Hypothetical Document Embeddings (HyDE)\n",
    "63.         hyde = HyDEQueryTransform(include_original=True, llm=self.llm)\n",
    "64. \n",
    "65.         transform_retriever = TransformRetriever(base_retriever, hyde)\n",
    "66. \n",
    "67.         retrieved_nodes = transform_retriever.retrieve(query_bundle)\n",
    "68.         return retrieved_nodes\n",
    "</snippet autocoder/index.py>\n",
    "<snippet autocoder/index.py start_line=0 end_line=23>\n",
    "0. from collections import defaultdict\n",
    "1. from dataclasses import dataclass\n",
    "2. from typing import Optional\n",
    "3. \n",
    "4. from llama_index import Document, ServiceContext, VectorStoreIndex\n",
    "5. from llama_index.embeddings import OpenAIEmbedding\n",
    "6. from llama_index.indices.query.query_transform import HyDEQueryTransform\n",
    "7. from llama_index.llms import OpenAI\n",
    "8. from llama_index.node_parser import CodeSplitter\n",
    "9. from llama_index.postprocessor import LLMRerank\n",
    "10. from llama_index.query_engine.transform_query_engine import TransformQueryEngine\n",
    "11. from llama_index.retrievers import TransformRetriever\n",
    "12. from llama_index.schema import QueryBundle\n",
    "13. \n",
    "14. \n",
    "15. @dataclass\n",
    "16. class QueryResult:\n",
    "17.     file_path: str\n",
    "18.     content: str\n",
    "19.     id: str\n",
    "20.     score: Optional[float] = None\n",
    "21.     metadata: Optional[dict] = None\n",
    "22.     start_char_idx: Optional[int] = None\n",
    "23.     end_char_idx: Optional[int] = None\n",
    "</snippet autocoder/index.py>\n",
    "<snippet autocoder/pydantic_models/context.py start_line=0 end_line=27>\n",
    "0. import os\n",
    "1. from collections import defaultdict\n",
    "2. from typing import List\n",
    "3. \n",
    "4. from actionweaver.actions.factories.pydantic_model_to_action import action_from_model\n",
    "5. from pydantic import BaseModel, Field\n",
    "6. \n",
    "7. from autocoder.telemetry import traceable\n",
    "8. \n",
    "9. assert os.environ[\"MODEL\"]\n",
    "10. MODEL = os.environ[\"MODEL\"]\n",
    "11. \n",
    "12. \n",
    "13. class Context(BaseModel):\n",
    "14.     questions_to_ask: List[str] = Field(\n",
    "15.         ...,\n",
    "16.         description=\"List of questions to ask the codebase to gather more context\",\n",
    "17.     )\n",
    "18. \n",
    "19.     file_name_mentioned_in_instruction: List[str] = Field(\n",
    "20.         default=[],\n",
    "21.         description=\"List of files mentioned in the instruction, e.g. file.py\",\n",
    "22.     )\n",
    "23. \n",
    "24.     object_identifiers: List[str] = Field(\n",
    "25.         default=[],\n",
    "26.         description=\"List of identifiers mentioned in the instruction, e.g. class name, function name, variable name\",\n",
    "27.     )\n",
    "</snippet autocoder/pydantic_models/context.py>\n",
    "<snippet autocoder/telemetry.py start_line=0 end_line=39>\n",
    "0. import os\n",
    "1. \n",
    "2. from actionweaver.llms import patch\n",
    "3. from langsmith.run_helpers import traceable as _traceable\n",
    "4. \n",
    "5. os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "6. os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "7. project_name = \"autocoder\"\n",
    "8. os.environ[\"LANGCHAIN_PROJECT\"] = project_name  # Optional: \"default\" is used if not set\n",
    "9. \n",
    "10. assert os.environ[\"LANGCHAIN_API_KEY\"]\n",
    "11. \n",
    "12. \n",
    "13. def identity_decorator(func):\n",
    "14.     def wrapper(*args, **kwargs):\n",
    "15.         result = func(*args, **kwargs)\n",
    "16.         return result\n",
    "17. \n",
    "18.     return wrapper\n",
    "19. \n",
    "20. \n",
    "21. def traceable(*args, **kwargs):\n",
    "22.     if os.environ.get(\"LANGCHAIN_API_KEY\"):\n",
    "23.         return _traceable(*args, **kwargs)\n",
    "24.     else:\n",
    "25.         return identity_decorator\n",
    "26. \n",
    "27. \n",
    "28. def trace_client(client):\n",
    "29.     if os.environ.get(\"LANGCHAIN_API_KEY\"):\n",
    "30.         client.chat.completions.create = traceable(name=\"llm_call\", run_type=\"llm\")(\n",
    "31.             client.chat.completions.create\n",
    "32.         )\n",
    "33.         client = patch(client)\n",
    "34.         client.chat.completions.create = traceable(\n",
    "35.             name=\"chat_completion_create\", run_type=\"llm\"\n",
    "36.         )(client.chat.completions.create)\n",
    "37.         return client\n",
    "38.     else:\n",
    "39.         return client\n",
    "</snippet autocoder/telemetry.py>\n",
    "<snippet main.py start_line=0 end_line=66>\n",
    "0. import os\n",
    "1. \n",
    "2. from langchain_community.utilities.github import GitHubAPIWrapper\n",
    "3. \n",
    "4. from autocoder.bot import AutoCoder\n",
    "5. from autocoder.codebase import Codebase\n",
    "6. from autocoder.index import RepositoryIndex\n",
    "7. \n",
    "8. assert os.environ[\"LANGCHAIN_API_KEY\"]\n",
    "9. assert os.environ[\"GITHUB_APP_ID\"]\n",
    "10. assert os.environ[\"GITHUB_APP_PRIVATE_KEY\"]\n",
    "11. \n",
    "12. \n",
    "13. # If use OpenAI API\n",
    "14. assert os.environ[\"OPENAI_API_KEY\"]\n",
    "15. \n",
    "16. \n",
    "17. os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "18. os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "19. \n",
    "20. project_name = \"autocoder\"\n",
    "21. os.environ[\"LANGCHAIN_PROJECT\"] = project_name  # Optional: \"default\" is used if not set\n",
    "22. \n",
    "23. \n",
    "24. def bold_green_string(text):\n",
    "25.     bold_green_text = \"\\033[1;32m\" + text + \"\\033[0m\"\n",
    "26.     return bold_green_text\n",
    "27. \n",
    "28. \n",
    "29. def bold_blue_string(text):\n",
    "30.     bold_blue_text = \"\\033[1;34m\" + text + \"\\033[0m\"\n",
    "31.     return bold_blue_text\n",
    "32. \n",
    "33. \n",
    "34. def stream_string_to_terminal(s, delay=0.1):\n",
    "35.     import time\n",
    "36. \n",
    "37.     for char in s:\n",
    "38.         print(char, end=\"\", flush=True)\n",
    "39.         time.sleep(delay)\n",
    "40.     print()  # for newline after streaming\n",
    "41. \n",
    "42. \n",
    "43. github_repository = \"TengHu/auto_coder\"\n",
    "44. github_api = GitHubAPIWrapper(\n",
    "45.     github_repository=github_repository,\n",
    "46.     github_app_id=os.environ[\"GITHUB_APP_ID\"],\n",
    "47.     github_app_private_key=os.environ[\"GITHUB_APP_PRIVATE_KEY\"],\n",
    "48. )\n",
    "49. codebase = Codebase(github_api)\n",
    "50. index = RepositoryIndex(github_api, github_repository, codebase)\n",
    "51. \n",
    "52. autocoder = AutoCoder(github_api, index, codebase)\n",
    "53. \n",
    "54. print(\n",
    "55.     bold_green_string(\"Welcome to AutoCoder! Enter your query or type 'exit' to leave\")\n",
    "56. )\n",
    "57. while True:\n",
    "58.     try:\n",
    "59.         user_input = input(bold_green_string(\"User :\"))\n",
    "60.         if user_input.lower() == \"exit\":\n",
    "61.             break\n",
    "62.         res = autocoder(user_input)\n",
    "63.         print(bold_blue_string(\"Assistant: \"))\n",
    "64.         stream_string_to_terminal(res, 0.01)\n",
    "65.     except KeyboardInterrupt:\n",
    "66.         break\n",
    "</snippet main.py>\n",
    "</context>\n",
    "<action_related_to_content_in: autocoder/bot.py>\n",
    "Replace the `OpenAI()` client instantiation with `AzureOpenAI()` and make sure that the environment variables for Azure are set properly for endpoint and API key. Comment out or remove the current OpenAI client instantiation code and replace it with AzureOpenAI code. The `self.client` should now use the AzureOpenAI client initialised with the proper endpoint and API key from the environment variables, conforming to the expected API version. Also, make sure to handle the import for AzureOpenAI at the beginning of the file.\n",
    "</action_related_to_content_in: autocoder/bot.py>\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1c0ec142-b796-43cb-a827-cd5fae889203",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": (\n",
    "            input\n",
    "        ),\n",
    "    },\n",
    "]\n",
    "blocks = create_blocks.invoke(\n",
    "    auto_coder.client,\n",
    "    messages=messages,\n",
    "    model='gpt-4-1106-preview',\n",
    "    stream=False,\n",
    "    force=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f788b734-70b4-4f15-ade4-8c6cdb37bf18",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def print_blocks(operations):\n",
    "    for o in operations:\n",
    "        print ('#' * 10)\n",
    "        # print(f\"\\nfirst_line_of_original_block:\\n{o.first_line_of_original_block}\")\n",
    "        # print(f\"\\nlast_line_of_original_block:\\n{o.last_line_of_original_block}\")\n",
    "        print(f\"\\nnew_code:\\n{o.new_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b09137a8-1e71-4ecc-905f-74d31ccbc06d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########\n",
      "\n",
      "new_code:\n",
      "        # self.client = trace_client(OpenAI())\n",
      "        self.client = trace_client(AzureOpenAI(\n",
      "            azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
      "            api_key=os.getenv(\"AZURE_OPENAI_KEY\"),\n",
      "            api_version=\"2023-10-01-preview\"\n",
      "        ))\n"
     ]
    }
   ],
   "source": [
    "print_blocks(blocks[0].operations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e7a650a5-d271-4ef5-89e9-ca0c33c7c794",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c14d91e6-92c8-4bd5-8c01-1c299c52481f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        self.client = trace_client(AzureOpenAI(\n",
      "            azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
      "            api_key=os.getenv(\"AZURE_OPENAI_KEY\"),\n",
      "            api_version=\"2023-10-01-preview\"\n",
      "        ))\n"
     ]
    }
   ],
   "source": [
    "print (\"        self.client = trace_client(AzureOpenAI(\\n            azure_endpoint=os.getenv(\\\"AZURE_OPENAI_ENDPOINT\\\"),\\n            api_key=os.getenv(\\\"AZURE_OPENAI_KEY\\\"),\\n            api_version=\\\"2023-10-01-preview\\\"\\n        ))\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ac9d72b-ce40-464a-9bfe-52bc3498bc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = \"\"\"Create a PR\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5140a5d7-c0d7-44fe-9cb4-1fae8e58a654",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autocoder.pydantic_models.context import create_context, gather_context\n",
    "res = gather_context(\"unused imports autocoder/bot\", auto_coder.client, index, codebase, add_line_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21801f8-c897-4270-b8e3-c4abb83d04e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c50e6dc6-e561-411a-b496-b4bc79f64ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autocoder.pydantic_models.code_block_ops import BlockOpOnLineIdx\n",
    "\n",
    "block = BlockOpOnLineIdx(\n",
    "        start_line_code = \"\",\n",
    "        start_line_idx=19, \n",
    "        end_line_idx=23, \n",
    "        old_code=\"// self.client = trace_client(AzureOpenAI(\\n//     azure_endpoint = os.getenv(\\\"AZURE_OPENAI_ENDPOINT\\\"),\\n//     api_key=os.getenv(\\\"AZURE_OPENAI_KEY\\\"),\\n//     api_version=\\\"2023-10-01-preview\\\"\\n// ))\\nself.client = trace_client(OpenAI())\",\n",
    "        new_code=\"self.client = trace_client(AzureOpenAI(\\n    azure_endpoint = os.getenv(\\\"AZURE_OPENAI_ENDPOINT\\\"),\\n    api_key=os.getenv(\\\"AZURE_OPENAI_KEY\\\"),\\n    api_version=\\\"latest version\\\"\\n))\\n// self.client = trace_client(OpenAI())\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d2084f6a-09ed-47eb-a4f5-c89429ec7296",
   "metadata": {},
   "outputs": [],
   "source": [
    "content = github_api.read_file(\"autocoder/bot.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c559a335-adb2-4b44-9f6d-d5e1876fc9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_code = block.find_block(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "af2df60e-4607-480e-a431-80858d257fa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        # self.client = trace_client(AzureOpenAI(\n",
      "        #     azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
      "        #     api_key=os.getenv(\"AZURE_OPENAI_KEY\"),\n",
      "        #     api_version=\"2023-10-01-preview\"\n",
      "        # ))\n"
     ]
    }
   ],
   "source": [
    "print (old_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1560df58-0448-4f42-8895-7448e1b0876a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.client = trace_client(AzureOpenAI(\n",
      "    azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
      "    api_key=os.getenv(\"AZURE_OPENAI_KEY\"),\n",
      "    api_version=\"latest version\"\n",
      "))\n",
      "// self.client = trace_client(OpenAI())\n"
     ]
    }
   ],
   "source": [
    "print (block.new_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd5faefd-139b-4938-846c-95b723876e19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.client = trace_client(AzureOpenAI(\n",
      "    azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
      "    api_key=os.getenv(\"AZURE_OPENAI_KEY\"),\n",
      "    api_version=\"2023-10-01-preview\"\n",
      "))\n"
     ]
    }
   ],
   "source": [
    "print (\"self.client = trace_client(AzureOpenAI(\\n    azure_endpoint = os.getenv(\\\"AZURE_OPENAI_ENDPOINT\\\"),\\n    api_key=os.getenv(\\\"AZURE_OPENAI_KEY\\\"),\\n    api_version=\\\"2023-10-01-preview\\\"\\n))\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f81df0b8-0e82-4cfb-8482-44a00e68658e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[System] Branch 'aw_demo_bot_v21' created successfully, and set as current active branch.\n"
     ]
    }
   ],
   "source": [
    "auto_coder = AutoCoder(github_api, index, codebase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8c7d2032-f8cc-46da-b39d-34be84833485",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "old = \"\"\"# self.client = trace_client(AzureOpenAI(\n",
    "#     azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "#     api_key=os.getenv(\"AZURE_OPENAI_KEY\"),\n",
    "#     api_version=\"2023-10-01-preview\"\n",
    "# ))\"\"\"\n",
    "new = \"self.client = trace_client(AzureOpenAI(\\n    azure_endpoint = os.getenv('AZURE_OPENAI_ENDPOINT'),\\n    api_key=os.getenv('AZURE_OPENAI_KEY'),\\n    api_version='2023-10-01-preview'))\"\n",
    "file_path = \"autocoder/bot.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2a46756f-492c-4636-9e99-8f11a36e5d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "content = f\"\"\"{file_path}\\nOLD <<<<\\n{old}\\n>>>> OLD\\nNEW <<<<\\n{new}\\n >>>> NEW\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f124a321-a535-49c6-bf89-3fd383e9533f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/Users/tenghu/Code/auto_coder/.venv/lib/python3.9/site-packages/langchain_community/utilities/github.py\u001b[0m(677)\u001b[0;36mupdate_file\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    675 \u001b[0;31m            \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    676 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 677 \u001b[0;31m            \u001b[0mfile_content\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    678 \u001b[0;31m            updated_file_content = file_content.replace(\n",
      "\u001b[0m\u001b[0;32m    679 \u001b[0;31m                \u001b[0mold_file_contents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_file_contents\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  print (file_query)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "autocoder/bot.py\n",
      "OLD <<<<\n",
      "# self.client = trace_client(AzureOpenAI(\n",
      "#     azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
      "#     api_key=os.getenv(\"AZURE_OPENAI_KEY\"),\n",
      "#     api_version=\"2023-10-01-preview\"\n",
      "# ))\n",
      ">>>> OLD\n",
      "NEW <<<<\n",
      "self.client = trace_client(AzureOpenAI(\n",
      "    azure_endpoint = os.getenv('AZURE_OPENAI_ENDPOINT'),\n",
      "    api_key=os.getenv('AZURE_OPENAI_KEY'),\n",
      "    api_version='2023-10-01-preview'))\n",
      " >>>> NEW\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  c\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'File content was not updated because old content was not found.It may be helpful to use the read_file action to get the current file contents.'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "github_api.update_file(content)\n",
    "#file_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41621da-8647-49b9-987c-5539bd212eae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5137b4db-2208-4faf-a479-17076da18e9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386f31e7-e9a2-49a3-96b4-a182706388a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = \"\"\"\n",
    "create a new file for each problem below with solution in lisp\n",
    "save these files under <proble_name>.lisp, e.g. problem1.lisp\n",
    "\n",
    "198. House Robber\n",
    "1. Two Sum\n",
    "2. Add Two Numbers\n",
    "3. Longest Substring Without Repeating Characters\n",
    "4. Median of Two Sorted Arrays\n",
    "\"\"\"\n",
    "\n",
    "input = \"\"\"\n",
    "find and remove unused imports in file autocoder/bot.\n",
    "\"\"\"\n",
    "\n",
    "input = \"\"\"[FILE UPDATE] Move the implementation of trace_client function into file autocoder/bot.py as a global function\"\"\"\n",
    "input = \"\"\"Refactor the RepositoryIndex class\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad6fbc4-e66a-408e-867d-b617b6703275",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73751d5b-cfaa-4885-8445-746a551da29c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I have successfully created a pull request with the number 73.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto_coder(\"create a pr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d16a64d-de27-430f-b742-7c045af08813",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = index.query(\"AutoCoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9d3d0e-232b-4f61-98a1-7eab421d7e37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "26a71e4f-054c-46d7-8a43-66b07fed9971",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai.types.chat.chat_completion_message import ChatCompletionMessage\n",
    "from openai.types.chat.chat_completion_message_tool_call import (\n",
    "    ChatCompletionMessageToolCall,\n",
    "Function\n",
    ")\n",
    "messages = [{'role': 'system',\n",
    "  'content': 'You are a coding assistant, you have the capability to assist with code-related tasks and modify files.'},\n",
    " {'role': 'user', 'content': 'Move trace_client function to bot.py.'},\n",
    " ChatCompletionMessage(content=None, role='assistant', tool_calls=[ChatCompletionMessageToolCall(id='call_9f2agXdE5nnUl1X04XkYHjeQ', function=Function(arguments='{\"description\":\"Move the \\'trace_client\\' function from its current location to the \\'bot.py\\' file.\"}', name='PlanCodeChange'), type='function')]),\n",
    " {'tool_call_id': 'call_9f2agXdE5nnUl1X04XkYHjeQ',\n",
    "  'role': 'tool',\n",
    "  'name': 'PlanCodeChange',\n",
    "  'content': \"- New files created: []\\n        - Existing files updated: [['Updated file autocoder/bot.py', 'Updated file autocoder/telemetry.py']]\\n        - Problems encountered: []\\n        ###\\n    Ignore others,    Make the previous message more user-friendly\\n        \"}\n",
    "           ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a1db6eea-8727-4b79-b971-217875e64fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "\n",
    "client = OpenAI()\n",
    "response = client.chat.completions.create(\n",
    "            model=\"gpt-4-1106-preview\",\n",
    "            messages=messages,\n",
    "            stream=False,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6933b5be-f2cb-42c8-8f10-e1ce1f89761e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-8h2sHwJwIR8SOkWxw2ypBGd80Uyom', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='I can assist you with moving the `trace_client` function to `bot.py`, but I need access to the source code or need to know where the current `trace_client` function is located. Can you provide the current code file that contains the `trace_client` function or tell me where to find it?', role='assistant', function_call=None, tool_calls=None))], created=1705269845, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_168383a679', usage=CompletionUsage(completion_tokens=63, prompt_tokens=135, total_tokens=198))\n"
     ]
    }
   ],
   "source": [
    "print (response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "09cb5b10-eda9-46e0-994d-60b2c5f86fb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I can assist you with moving the `trace_client` function to `bot.py`, but I need access to the source code or need to know where the current `trace_client` function is located. Can you provide the current code file that contains the `trace_client` function or tell me where to find it?\n"
     ]
    }
   ],
   "source": [
    "print (response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "50c37b99-db67-4367-8771-a284e4dfab57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a coding assistant, you have the capability to assist with code-related tasks and modify files.\n"
     ]
    }
   ],
   "source": [
    "print (messages[0]['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "df5b7a06-951b-4cc2-b7d2-cbbc864410b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': 'You are a coding assistant, you have the capability to assist with code-related tasks and modify files.'},\n",
       " {'role': 'user', 'content': 'Move trace_client function to bot.py.'},\n",
       " ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_9f2agXdE5nnUl1X04XkYHjeQ', function=Function(arguments='{\"description\":\"Move the \\'trace_client\\' function from its current location to the \\'bot.py\\' file.\"}', name='PlanCodeChange'), type='function')]),\n",
       " {'tool_call_id': 'call_9f2agXdE5nnUl1X04XkYHjeQ',\n",
       "  'role': 'tool',\n",
       "  'name': 'PlanCodeChange',\n",
       "  'content': \"I've read code and attempted to create code changes. The outcome of these code changes is as follows:\\n        - New files created: []\\n        - Existing files updated: [['Updated file autocoder/bot.py', 'Updated file autocoder/telemetry.py']]\\n        - Problems encountered: []\\n        ###\\n        Make the previous message more user-friendly\\n        \"}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2939b91a-fe15-4338-a52a-d4a7da7a1aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autocoder.pydantic_models_v2 import create_implementation_plan\n",
    "messages = [{\"role\": \"user\", \"content\": user_prompt}]\n",
    "\n",
    "implementation_plan = create_implementation_plan.invoke(\n",
    "    auto_coder.client,\n",
    "    messages=messages,\n",
    "    temperature=1,\n",
    "    model=os.environ[\"MODEL\"],\n",
    "    stream=False,\n",
    "    force=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c11904e-43cc-4173-908f-9e5244150971",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[FileModification(file_path='autocoder/bot.py', instruction='Remove unused import statements')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "implementation_plan[0].file_modifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f9787ea-3f14-40ca-abba-d13cb143d1bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ImplementationPlan(chain_of_thought='To identify and remove any unused imports in autocoder/bot.py, we need to first determine which imports are not being used in the file. This can be accomplished by analyzing the content of bot.py to see which imported modules and objects are not referenced anywhere in the code. Once we identify the unused imports, we can create a plan to remove these lines from the file.\\n\\nThe specific steps are to:\\n1. Analyze the file autocoder/bot.py to find all the import statements.\\n2. Determine which imports are not used in the rest of the file.\\n3. Remove the lines containing the unused imports.\\n4. Test to ensure that the removal of the imports does not affect the functionality of the script.\\n', file_modifications=[FileModification(file_path='autocoder/bot.py', instruction='Remove unused import statements')], file_creations=[])]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "implementation_plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "551fca6a-f3c2-48d1-aa38-dcd502055ae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Represents a plan to implement a feature, a plan include file creation/modification operations.\n",
      "\n",
      "    Example:\n",
      "        plan = ImplementationPlan(\n",
      "            chain_of_thought=\"Plan to refactor existing code.\",\n",
      "            file_modifications=[\n",
      "                FileModification(\n",
      "                    \n",
      "                    blocks=[\n",
      "        Block(\n",
      "            step_by_step_instruction_rewrite_the_block=\"Refactor a method called `foo` that takes a parameter named `bar` and returns `bar`\",\n",
      "            start_newline_of_interested_block=\"def foo(bar):\",\n",
      "            end_newline_of_interested_block=\"return bar\"\n",
      "        )\n",
      "        ]\n",
      "                )\n",
      "            ],\n",
      "            file_creations=[\n",
      "                FileCreation(\n",
      "                    file_name=\"new_feature.py\",\n",
      "                    content=\"def new_function():\n",
      "    # Add new feature code here\",\n",
      "                )\n",
      "            ],\n",
      "        )\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "from autocoder.pydantic_models_v2 import ImplementationPlan\n",
    "print (ImplementationPlan.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "412d9f50-be8d-4f9c-b166-59ba5f876748",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import os'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "implementation_plan[0].file_modifications[0].blocks[0].find_block(user_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dcf75302-039f-44d8-a7da-791176d6db85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matching Substring: apple pe\n"
     ]
    }
   ],
   "source": [
    "import difflib\n",
    "\n",
    "# Sample strings for comparison\n",
    "string1 = \"apple pie\"\n",
    "string2 = \"apples and pears\"\n",
    "\n",
    "# Calculate matching blocks\n",
    "matcher = difflib.SequenceMatcher(None, string1, string2)\n",
    "matching_blocks = matcher.get_matching_blocks()\n",
    "\n",
    "# Extract matching substring\n",
    "matching_substring = \"\"\n",
    "for block in matching_blocks:\n",
    "    i, j, length = block\n",
    "    matching_substring += string1[i:i + length]\n",
    "\n",
    "print(f\"Matching Substring: {matching_substring}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b9815535-b07a-4ba3-89c9-fb6374dbab44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' are awesome animal catterpillar who like other humans but not other caterpilar'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_here[s[1].a: s[1].b + s[1].size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b7f3ecef-9c3b-4420-80fb-ce5121036905",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21782178217821782"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.ratio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e24e29-2df1-46c3-9fed-e60eeb76e965",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
